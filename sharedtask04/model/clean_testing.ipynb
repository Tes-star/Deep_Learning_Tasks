{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import data\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "df_train=pd.read_csv('../data/01_train/train.tsv', sep='\\t',\n",
    "            header=0,\n",
    "            names = [\"Nr\",\"Wort\",\"Typ1\",\"Typ2\"],\n",
    "            quoting=csv.QUOTE_NONE                     ,\n",
    "                     keep_default_na=False,\n",
    "                     encoding='utf-8')\n",
    "\n",
    "df_train = df_train.drop(df_train[df_train['Nr']=='#'].index)\n",
    "df_train=df_train.reset_index(drop=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [],
   "source": [
    "'Label dict filter'\n",
    "outside =0\n",
    "label_dict = {\n",
    "    'B-LOC': 1,\n",
    "    'I-LOC': 2,\n",
    "    'B-PER': 3,\n",
    "    'I-PER': 4,\n",
    "    'B-ORG': 5,\n",
    "    'I-ORG': 6,\n",
    "    'B-LOCderiv': outside,\n",
    "    \"B-LOCpart\": outside,\n",
    "    'B-ORGderiv': outside,\n",
    "    'B-ORGpart': outside,\n",
    "    'B-OTH': outside,\n",
    "    'B-OTHderiv': outside,\n",
    "    'B-OTHpart': outside,\n",
    "    'B-PERderiv': outside,\n",
    "    'B-PERpart': outside,\n",
    "    'I-LOCderiv': outside,\n",
    "    'I-LOCpart': outside,\n",
    "    'I-ORGpart': outside,\n",
    "    'I-OTH': outside,\n",
    "    'I-OTHderiv': outside,\n",
    "    'I-OTHpart': outside,\n",
    "    'I-PERderiv': outside,\n",
    "    'I-PERpart': outside,\n",
    "    'O': outside\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "tokens=[]\n",
    "labels=[]\n",
    "ids=[]\n",
    "\n",
    "sentence_token=[]\n",
    "sentence_labels=[]\n",
    "sentence_ids=[]\n",
    "\n",
    "i=0\n",
    "\n",
    "id=0\n",
    "for j in range(0, len(df_train)):\n",
    "    if i > 0 and df_train.Nr[j] == '1':\n",
    "        tokens.append(sentence_token)\n",
    "        labels.append(sentence_labels)\n",
    "\n",
    "        sentence_token, sentence_labels = [], []\n",
    "        ids.append(id)\n",
    "        id = id + 1\n",
    "\n",
    "    sentence_token.append(str(df_train.Wort[j]))\n",
    "    # sentence_labels.append(df_train.Typ1[j])\n",
    "    sentence_labels.append(label_dict.get(df_train.Typ1[j]))\n",
    "\n",
    "    i = i + 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "data": {
      "text/plain": "'Data Preprocessing'"
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Data Preprocessing'\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [
    {
     "data": {
      "text/plain": "'label alignment'"
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'label alignment'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [],
   "source": [
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "conll = {'train':Dataset.from_dict({'id':ids,'tokens':tokens,'ner_tags':labels})\n",
    "    ,'validation':Dataset.from_dict({'id':ids[10:11],'tokens':tokens[10:11],'ner_tags':labels[10:11]})\n",
    "     #'test':Dataset.from_dict({'label':y_test,'text':x_test})\n",
    "     }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [],
   "source": [
    "from datasets import Dataset, ClassLabel, Sequence, Features, Value\n",
    "\n",
    "\n",
    "d = {'id':ids ,'ner_tags': labels, 'tokens': tokens}\n",
    "# define number of tags and their names\n",
    "tags = ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'])\n",
    "# create dataset\n",
    "ds ={'train':     Dataset.from_dict(mapping=d, features=Features({\"ner_tags\":Sequence(tags),  'id': Value(dtype='string'),  'tokens': Sequence(feature=Value(dtype='string'))})),\n",
    "     'validation':Dataset.from_dict(mapping=d, features=Features({\"ner_tags\":Sequence(tags),  'id': Value(dtype='string'),  'tokens': Sequence(feature=Value(dtype='string'))}))\n",
    "\n",
    "     }\n",
    "# access ClassLabel feature - 0 returns tag \"O\", 1 returns \"B-PER\" etc\n",
    "#ds['train'].features[\"ner_tags\"].feature.int2str(0)\n",
    "#conll=ds\n",
    "conll=ds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [
    {
     "data": {
      "text/plain": "[[3, 0, 0, 0, 5, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 5, 6, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 4, 0, 0, 0, 5, 6, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n [0, 3, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  6,\n  6,\n  6,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 5, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [3,\n  4,\n  4,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  2,\n  2,\n  0],\n [0,\n  0,\n  0,\n  5,\n  6,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 1, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  3,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  2,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 5, 0, 1, 2, 0, 0],\n [3, 4, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 3, 4, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  1,\n  2,\n  2,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 1, 0, 0, 0, 0, 0, 1, 2, 0],\n [0, 5, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  3,\n  0,\n  3,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 5, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 1, 0, 0, 0],\n [0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 1, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [1, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 1, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 3, 4],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 3, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  5,\n  0],\n [0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [3, 4, 0, 3, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 3, 4, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0],\n [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  6,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 1, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 4, 0, 0],\n [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  0,\n  0,\n  5,\n  6,\n  0,\n  0,\n  0,\n  0,\n  0],\n [3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 1, 0],\n [0, 0, 1, 2, 0, 1, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 3, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0],\n [0, 0, 1, 0, 0, 3, 4, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n [0, 0, 1, 2, 0, 1, 2, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  0],\n [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [3, 4, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  2,\n  0],\n [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n [0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  6,\n  6,\n  0,\n  0,\n  0,\n  1,\n  2,\n  2,\n  2,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  6,\n  6,\n  0,\n  0,\n  5,\n  6,\n  6,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 3, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [5,\n  6,\n  6,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 6, 6, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 5, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 3, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  3,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0],\n [0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [1,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 5, 6, 6, 6, 6, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 5, 0, 0, 0, 0, 0, 1, 0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 1, 0, 0, 0, 0, 0, 5, 0, 0, 5],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  5,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  1,\n  0,\n  1,\n  0,\n  0,\n  0,\n  1,\n  2,\n  0,\n  0,\n  0,\n  1,\n  2,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 5, 6, 0, 0, 3, 4, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 5, 6, 6, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 5, 6, 6, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  5,\n  6,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 1, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 5, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0],\n [0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [1, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  3,\n  4,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n [0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n [5, 6, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0],\n [0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 3, 0, 3, 4, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0],\n [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 5, 6, 3, 4, 0, 0, 0, 5, 6, 6, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 1, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 5, 6, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0],\n [0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0],\n [0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [5,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  1,\n  0,\n  1,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  2,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0],\n [0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 3, 4, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 1, 2, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  1,\n  2,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 5, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 5, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  1,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 3, 0, 3, 0, 3, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 3, 4, 0, 0, 0, 0, 0],\n [0,\n  0,\n  1,\n  2,\n  2,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 3, 0, 5, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 5, 6, 6, 6, 6, 0, 0, 0, 1, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n [1, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0],\n [0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 1, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [1, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0],\n [0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  5,\n  6,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  5,\n  0,\n  5,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  1,\n  0,\n  5,\n  0,\n  5,\n  6,\n  0],\n [0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  6,\n  0,\n  5,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  3,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 5, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  2,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [3, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 3, 4, 0, 0, 0, 0, 0, 0, 0],\n [3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  1,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  1,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  5,\n  6,\n  6,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  5,\n  6,\n  6,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0],\n [0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 2, 0],\n [0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 5, 6, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0],\n [3, 4, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [5, 0, 0, 0, 0, 0, 0, 0, 5, 0],\n [0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 6, 6, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 5],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 5, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 5, 0, 0, 0, 0, 5],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  1,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 1, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 3, 4, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 3, 4, 0, 1, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  6,\n  6,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  3,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  6,\n  0,\n  0,\n  5,\n  6,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 5, 6, 6, 0, 3, 4, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n [3, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 1, 0, 5, 0, 0, 0, 0],\n [0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 5, 6, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n [0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  3,\n  4,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  5,\n  6,\n  0,\n  5,\n  6,\n  6,\n  6,\n  6,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n [0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 5, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 1, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 5, 0, 0, 0, 0, 0],\n [0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0],\n [0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0],\n [0, 0, 3, 0, 1, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [3, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 5, 6, 0],\n [3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 3, 4, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  3,\n  0,\n  3,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [3, 4, 0, 0, 0, 1, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 5, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 1, 0, 0, 0, 1, 2, 2, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  4,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 3, 0, 0, 5, 6, 0, 0, 0, 1, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0],\n [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  5,\n  6,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n [0, 0, 0, 0, 3, 4, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 1, 2, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  4,\n  4,\n  0,\n  5,\n  0,\n  0,\n  0,\n  5,\n  6,\n  6,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  6,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 3, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 3, 0, 0, 0, 0, 0, 1, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  1,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  5,\n  6,\n  6,\n  6,\n  6,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0],\n [0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [1,\n  0,\n  5,\n  6,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  6,\n  0],\n [3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [1, 5, 0, 3, 4, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 3, 4, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0],\n [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 3, 4, 0, 0, 1, 0, 1, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [5, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n [0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  5,\n  6,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  5,\n  6,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0],\n [0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 5, 0, 0, 0],\n [3, 0, 3, 0, 0],\n [0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, 1, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [3, 4, 0, 0, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0],\n [0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 5, 0, 0],\n [0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0],\n [1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 3, 4, 0, 5, 6, 0, 1, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 5, 6, 0, 3, 4, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 3, 4, 4, 0, 0, 0, 0, 5, 6, 0],\n [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 5, 0],\n [0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 6, 0, 0],\n [0,\n  5,\n  6,\n  0,\n  0,\n  0,\n  1,\n  0,\n  5,\n  6,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  5,\n  6,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 3, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 3, 4, 4, 4, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  5,\n  6,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 0],\n [0, 5, 0, 0, 0, 0, 0, 0, 5, 6, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [3,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [1, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0],\n [3, 4, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0],\n [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0],\n [0, 5, 6, 0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 5, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0],\n [0,\n  0,\n  3,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  1,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0],\n [0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0],\n [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 3, 4, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0],\n [3, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 3, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 5, 6, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  4,\n  4,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 3, 4, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n [3, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0],\n [3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 3, 4, 0, 0, 0, 0],\n [3, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n [0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  0,\n  3,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  3,\n  4,\n  0,\n  0,\n  0,\n  1,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0],\n [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [5,\n  0,\n  0,\n  0,\n  5,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n ...]"
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 0, 0, 5, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['Schartau', 'sagte', 'dem', '\"', 'Tagesspiegel', '\"', 'vom', 'Freitag', ',', 'Fischer', 'sei', '\"', 'in', 'einer', 'Weise', 'aufgetreten', ',', 'die', 'alles', 'andere', 'als', 'überzeugend', 'war', '\"', '.']\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "print(conll['train'][0]['ner_tags'])\n",
    "print(conll['train'][0]['tokens'])\n",
    "\n",
    "# print(conll['train'][1]['ner_tags'])\n",
    "# print(conll['train'][1]['tokens'])\n",
    "#\n",
    "# print(conll['train'][2]['ner_tags'])\n",
    "# print(conll['train'][2]['tokens'])\n",
    "#\n",
    "# print(conll['train'][3]['ner_tags'])\n",
    "# print(conll['train'][3]['tokens'])\n",
    "#\n",
    "# print(conll['train'][4]['ner_tags'])\n",
    "# print(conll['train'][4]['tokens'])\n",
    "#\n",
    "# print(conll['train'].features['ner_tags'])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [
    {
     "data": {
      "text/plain": "['[CLS]',\n 'Schar',\n '##ta',\n '##u',\n 'sagte',\n 'dem',\n '\"',\n 'Tages',\n '##spiegel',\n '\"',\n 'vom',\n 'Freitag',\n ',',\n 'Fischer',\n 'sei',\n '\"',\n 'in',\n 'einer',\n 'Weise',\n 'aufgetreten',\n ',',\n 'die',\n 'alles',\n 'andere',\n 'als',\n 'überzeugen',\n '##d',\n 'war',\n '\"',\n '.',\n '[SEP]']"
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "'inferenz'\n",
    "model_name = 'deepset/gbert-base'\n",
    "# model_name='jplu/tf-xlm-r-ner-40-lang'\n",
    "# model_name='Davlan/bert-base-multilingual-cased-ner-hrl'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "inputs = tokenizer(conll['train'][0]['tokens'], is_split_into_words=True)\n",
    "inputs.tokens()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tokenize_and_align_labels(sequence_batch):\n",
    "    # tokenize pre-tokenized sequences\n",
    "    # long sequences will be truncated to respect the maximum token length of the language model (usually 512)\n",
    "    tokenized_sequences = tokenizer(sequence_batch['tokens'], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    # iterate over pre-tokenized tokens of single sequences\n",
    "    for i, label in enumerate(sequence_batch['ner_tags']):\n",
    "        # get associated word ids of the subtokens\n",
    "        # if a token has multiple subtokens, then each subtoken is associated with the token's word id\n",
    "        word_ids = tokenized_sequences.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        # iterate over subtokens\n",
    "        for word_idx in word_ids:\n",
    "            # special tokens (e.g. [CLS], [SEP]) get label id -100 -> loss function will ignore them\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # if the first subtoken of the next token is encountered, then associate the token's ner label with the subtoken\n",
    "            # FIXME what if two consecutive tokens are identical (e.g. \"is this a really really bad?\")?\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # consecutive subtokens will be ignored\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            # memorize the current word\n",
    "            previous_word_idx = word_idx\n",
    "        # add labels of the current sequence to the list of labels of the batch\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    # update batch labels\n",
    "    tokenized_sequences['labels'] = labels\n",
    "    return tokenized_sequences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [
    "# # test\n",
    "# example_ner_tag=conll['train'][0]['ner_tags']\n",
    "# print(example_ner_tag)\n",
    "# exampletokens=conll['train'][0]['tokens']\n",
    "# print(exampletokens)\n",
    "# example={'tokens':exampletokens,'ner_tags':example_ner_tag}\n",
    "# emaple_prepocessed=tokenize_and_align_labels(example)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['B-LOC', 'B-LOCderiv', 'B-LOCpart', 'B-ORG', 'B-ORGderiv',\n       'B-ORGpart', 'B-OTH', 'B-OTHderiv', 'B-OTHpart', 'B-PER',\n       'B-PERderiv', 'B-PERpart', 'I-LOC', 'I-LOCderiv', 'I-LOCpart',\n       'I-ORG', 'I-ORGpart', 'I-OTH', 'I-OTHderiv', 'I-OTHpart', 'I-PER',\n       'I-PERderiv', 'I-PERpart', 'O'], dtype=object)"
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import unique\n",
    "\n",
    "unique(df_train.Typ1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [],
   "source": [
    "# tf_train_set = model.prepare_tf_dataset(\n",
    "#     conll['train'].map(tokenize_and_align_labels, batched=True),\n",
    "#     shuffle=True,\n",
    "#     batch_size=1,\n",
    "#     collate_fn=data_collator,\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [],
   "source": [
    "#conll['train'][0]['pos_tags']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "#conll['train'].features['pos_tags']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from keras.losses import BinaryCrossentropy, CategoricalCrossentropy, SparseCategoricalCrossentropy, Hinge\n",
    "from transformers import TFAutoModelForTokenClassification, create_optimizer\n",
    "\n",
    "'LMtraining'\n",
    "\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(model_name, num_labels=7,id2label={0:'O',1: 'B-PER', 2:'I-PER',3: 'B-ORG',4: 'I-ORG',5: 'B-LOC', 6:'I-LOC'}) #label2id\n",
    "batch_size = 320\n",
    "num_train_epochs = 30\n",
    "num_train_steps = (len(conll['train']) // batch_size) * num_train_epochs\n",
    "optimizer, lr_schedule = create_optimizer(\n",
    "    init_lr=2e-5,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.01,\n",
    "    num_warmup_steps=0,\n",
    ")\n",
    "\n",
    "model.get_layer('bert').trainable=False\n",
    "#SparseCategoricalCrossentropy(from_logits=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer,  metrics=[\"accuracy\"])\n",
    "#model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c519076b0c9a45a89d9ceca0800ae85b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "C:\\Users\\Timo\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:715: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "efff6bd0d9dd476b8c70b3ae8b14c60b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, return_tensors=\"tf\")\n",
    "tf_train_set = model.prepare_tf_dataset(\n",
    "    conll['train'].map(tokenize_and_align_labels, batched=True),\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_validation_set = model.prepare_tf_dataset(\n",
    "    conll['validation'].map(tokenize_and_align_labels, batched=True),\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Timo\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:715: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 136s 2s/step - loss: 0.0830 - accuracy: 0.9804 - val_loss: 0.0621 - val_accuracy: 0.2840 - precision: 0.7541 - recall: 0.7943 - f1: 0.7737\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 121s 2s/step - loss: 0.0688 - accuracy: 0.9820 - val_loss: 0.0569 - val_accuracy: 0.2845 - precision: 0.7659 - recall: 0.8236 - f1: 0.7937\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 121s 2s/step - loss: 0.0651 - accuracy: 0.9828 - val_loss: 0.0542 - val_accuracy: 0.2847 - precision: 0.7741 - recall: 0.8312 - f1: 0.8017\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 120s 2s/step - loss: 0.0634 - accuracy: 0.9832 - val_loss: 0.0526 - val_accuracy: 0.2848 - precision: 0.7813 - recall: 0.8357 - f1: 0.8076\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 120s 2s/step - loss: 0.0624 - accuracy: 0.9835 - val_loss: 0.0515 - val_accuracy: 0.2849 - precision: 0.7835 - recall: 0.8419 - f1: 0.8117\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 120s 2s/step - loss: 0.0618 - accuracy: 0.9838 - val_loss: 0.0507 - val_accuracy: 0.2850 - precision: 0.7874 - recall: 0.8451 - f1: 0.8152\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 120s 2s/step - loss: 0.0613 - accuracy: 0.9839 - val_loss: 0.0500 - val_accuracy: 0.2850 - precision: 0.7884 - recall: 0.8451 - f1: 0.8158\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 121s 2s/step - loss: 0.0609 - accuracy: 0.9841 - val_loss: 0.0497 - val_accuracy: 0.2851 - precision: 0.7894 - recall: 0.8491 - f1: 0.8182\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 120s 2s/step - loss: 0.0608 - accuracy: 0.9842 - val_loss: 0.0491 - val_accuracy: 0.2851 - precision: 0.7903 - recall: 0.8497 - f1: 0.8189\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 120s 2s/step - loss: 0.0600 - accuracy: 0.9842 - val_loss: 0.0491 - val_accuracy: 0.2851 - precision: 0.7902 - recall: 0.8535 - f1: 0.8207\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 120s 2s/step - loss: 0.0600 - accuracy: 0.9844 - val_loss: 0.0484 - val_accuracy: 0.2852 - precision: 0.7946 - recall: 0.8490 - f1: 0.8209\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 120s 2s/step - loss: 0.0601 - accuracy: 0.9845 - val_loss: 0.0483 - val_accuracy: 0.2852 - precision: 0.7956 - recall: 0.8517 - f1: 0.8227\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 120s 2s/step - loss: 0.0598 - accuracy: 0.9845 - val_loss: 0.0482 - val_accuracy: 0.2852 - precision: 0.7935 - recall: 0.8548 - f1: 0.8230\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 120s 2s/step - loss: 0.0596 - accuracy: 0.9846 - val_loss: 0.0480 - val_accuracy: 0.2852 - precision: 0.7954 - recall: 0.8546 - f1: 0.8239\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 120s 2s/step - loss: 0.0592 - accuracy: 0.9846 - val_loss: 0.0481 - val_accuracy: 0.2852 - precision: 0.7953 - recall: 0.8568 - f1: 0.8249\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 121s 2s/step - loss: 0.0595 - accuracy: 0.9846 - val_loss: 0.0478 - val_accuracy: 0.2852 - precision: 0.7956 - recall: 0.8542 - f1: 0.8238\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 120s 2s/step - loss: 0.0594 - accuracy: 0.9847 - val_loss: 0.0475 - val_accuracy: 0.2853 - precision: 0.7982 - recall: 0.8542 - f1: 0.8253\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 120s 2s/step - loss: 0.0589 - accuracy: 0.9848 - val_loss: 0.0475 - val_accuracy: 0.2853 - precision: 0.7991 - recall: 0.8566 - f1: 0.8269\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 120s 2s/step - loss: 0.0595 - accuracy: 0.9847 - val_loss: 0.0476 - val_accuracy: 0.2853 - precision: 0.7959 - recall: 0.8594 - f1: 0.8265\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 119s 2s/step - loss: 0.0593 - accuracy: 0.9848 - val_loss: 0.0473 - val_accuracy: 0.2853 - precision: 0.7978 - recall: 0.8560 - f1: 0.8259\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 120s 2s/step - loss: 0.0595 - accuracy: 0.9848 - val_loss: 0.0472 - val_accuracy: 0.2853 - precision: 0.7991 - recall: 0.8556 - f1: 0.8264\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 121s 2s/step - loss: 0.0588 - accuracy: 0.9847 - val_loss: 0.0474 - val_accuracy: 0.2853 - precision: 0.7971 - recall: 0.8591 - f1: 0.8269\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 121s 2s/step - loss: 0.0587 - accuracy: 0.9847 - val_loss: 0.0472 - val_accuracy: 0.2853 - precision: 0.7973 - recall: 0.8573 - f1: 0.8262\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 120s 2s/step - loss: 0.0587 - accuracy: 0.9848 - val_loss: 0.0468 - val_accuracy: 0.2853 - precision: 0.8005 - recall: 0.8540 - f1: 0.8264\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 121s 2s/step - loss: 0.0593 - accuracy: 0.9847 - val_loss: 0.0473 - val_accuracy: 0.2853 - precision: 0.7962 - recall: 0.8593 - f1: 0.8266\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 121s 2s/step - loss: 0.0591 - accuracy: 0.9848 - val_loss: 0.0469 - val_accuracy: 0.2853 - precision: 0.7984 - recall: 0.8561 - f1: 0.8262\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 122s 2s/step - loss: 0.0592 - accuracy: 0.9848 - val_loss: 0.0470 - val_accuracy: 0.2853 - precision: 0.7969 - recall: 0.8569 - f1: 0.8258\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 121s 2s/step - loss: 0.0586 - accuracy: 0.9849 - val_loss: 0.0470 - val_accuracy: 0.2853 - precision: 0.8007 - recall: 0.8579 - f1: 0.8283\n",
      "Epoch 29/100\n",
      "68/75 [==========================>...] - ETA: 3s - loss: 0.0600 - accuracy: 0.2840"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "\n",
    "    #label_list = [0,1,2,3,4,5,6]\n",
    "#\n",
    "    label_list =ds['train'].features[\"ner_tags\"].feature.names\n",
    "    #label_list = tf_train_set.features[f\"ner_tags\"].feature.names\n",
    "\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "\n",
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_train_set)\n",
    "model.compile(optimizer=\"adam\",  # loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "#model.summary()\n",
    "import os\n",
    "os.environ[\"XLA_FLAGS\"]=\"--xla_gpu_cuda_data_dir=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.8\"\n",
    "model.fit(x=tf_train_set, validation_data=tf_train_set, epochs=100,callbacks=metric_callback)\n",
    "#82,83"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0 0 0 0 0 0 0 0 1 0]], shape=(1, 10), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O']"
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# from huggingface\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "text=\"Kartoffel test ist eine schöne Stadt in München\"\n",
    "inputs_tokens = tokenizer(text, return_tensors=\"tf\")\n",
    "\n",
    "logits = model(**inputs_tokens).logits\n",
    "#Get the class with the highest probability, and use the model’s id2label mapping to convert it to a text label:\n",
    "\n",
    "\n",
    "predicted_token_class_ids = tf.math.argmax(logits, axis=-1)\n",
    "print(predicted_token_class_ids)\n",
    "predicted_token_class = [model.config.id2label[t] for t in predicted_token_class_ids[0].numpy().tolist()]\n",
    "predicted_token_class\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=\narray([[  102, 28410, 30028,   215,   261,  8668,   668,   153,  2591,\n          103]])>, 'token_type_ids': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>, 'attention_mask': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])>}"
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with subtokens\n",
      "pred_label: O  :  102  :  [CLS]\n",
      "pred_label: O  :  28410  :  Kartoffel\n",
      "pred_label: O  :  30028  :  test\n",
      "pred_label: O  :  215  :  ist\n",
      "pred_label: O  :  261  :  eine\n",
      "pred_label: O  :  8668  :  schöne\n",
      "pred_label: O  :  668  :  Stadt\n",
      "pred_label: O  :  153  :  in\n",
      "pred_label: B-PER  :  2591  :  München\n",
      "pred_label: O  :  103  :  [SEP]\n",
      "\n",
      "without subtokens\n",
      "pred_label: O  :  102  :  [CLS]\n",
      "pred_label: O  :  28410  :  Kartoffel\n",
      "pred_label: O  :  30028  :  test\n",
      "pred_label: O  :  215  :  ist\n",
      "pred_label: O  :  261  :  eine\n",
      "pred_label: O  :  8668  :  schöne\n",
      "pred_label: O  :  668  :  Stadt\n",
      "pred_label: O  :  153  :  in\n",
      "pred_label: B-PER  :  2591  :  München\n",
      "pred_label: O  :  103  :  [SEP]\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O']\n"
     ]
    }
   ],
   "source": [
    "subtoken=False\n",
    "\n",
    "pred_labels=[]\n",
    "\n",
    "ner_labels=[]\n",
    "ner_labels_subtokens=[]\n",
    "print('with subtokens')\n",
    "for pred_label,subtoken in zip(predicted_token_class,inputs_tokens.input_ids.numpy()[0]):\n",
    "    word=tokenizer.decode([subtoken])\n",
    "    print(\"pred_label:\", pred_label, \" : \", subtoken, \" : \", word)\n",
    "\n",
    "print()\n",
    "print('without subtokens')\n",
    "for pred_label,subtoken in zip(predicted_token_class,inputs_tokens.input_ids.numpy()[0]):\n",
    "    word=str(tokenizer.decode([subtoken]))\n",
    "\n",
    "\n",
    "\n",
    "    if word[:2]== \"##\" :\n",
    "        ner_labels_subtokens.append(pred_label)\n",
    "        subtoken=True\n",
    "    else:\n",
    "        if subtoken==True:\n",
    "            ner_labels.append(ner_labels_subtokens[0])\n",
    "            ner_labels_subtokens=[]\n",
    "            subtoken=False\n",
    "        else:\n",
    "            ner_labels.append(pred_label)\n",
    "        print(\"pred_label:\", pred_label, \" : \", subtoken, \" : \", word)\n",
    "\n",
    "\n",
    "print(ner_labels)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_labels_subtokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': <tf.Tensor: shape=(1, 13), dtype=int32, numpy=\narray([[  102, 28410, 14359,  7838,   888, 14359,  7838,   888, 14359,\n         7838,   888, 28410,   103]])>, 'token_type_ids': <tf.Tensor: shape=(1, 13), dtype=int32, numpy=array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>, 'attention_mask': <tf.Tensor: shape=(1, 13), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])>}"
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"Kartoffel  Arschficken Arschficken Arschficken Kartoffel \"\n",
    "inputs = tokenizer(text, return_tensors=\"tf\")\n",
    "inputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [
    {
     "data": {
      "text/plain": "'[CLS] Kartoffel arschficken ist eine schöne Stadt in München [SEP]'"
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs.input_ids.numpy()[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [238], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m tokenizer\u001B[38;5;241m.\u001B[39mdecode(\u001B[43minputs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokens\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m()[\u001B[38;5;241m0\u001B[39m])\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'function' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "tokenizer.decode(inputs.tokens)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 102, 8668,  668,  153, 2591,  103]])"
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids.numpy()[0]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PreTokenizedEncodeInput must be Union[PreTokenizedInputSequence, Tuple[PreTokenizedInputSequence, PreTokenizedInputSequence]]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [223], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mObama was the president of the United States and he was born in Hawai.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 3\u001B[0m encoding \u001B[38;5;241m=\u001B[39m \u001B[43mtokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mis_split_into_words\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# forward pass\u001B[39;00m\n\u001B[0;32m      5\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mencoding)\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2488\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.__call__\u001B[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m   2486\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_in_target_context_manager:\n\u001B[0;32m   2487\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_input_mode()\n\u001B[1;32m-> 2488\u001B[0m     encodings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_one(text\u001B[38;5;241m=\u001B[39mtext, text_pair\u001B[38;5;241m=\u001B[39mtext_pair, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mall_kwargs)\n\u001B[0;32m   2489\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m text_target \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2490\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_target_mode()\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2594\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase._call_one\u001B[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m   2574\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_encode_plus(\n\u001B[0;32m   2575\u001B[0m         batch_text_or_text_pairs\u001B[38;5;241m=\u001B[39mbatch_text_or_text_pairs,\n\u001B[0;32m   2576\u001B[0m         add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2591\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   2592\u001B[0m     )\n\u001B[0;32m   2593\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2594\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencode_plus(\n\u001B[0;32m   2595\u001B[0m         text\u001B[38;5;241m=\u001B[39mtext,\n\u001B[0;32m   2596\u001B[0m         text_pair\u001B[38;5;241m=\u001B[39mtext_pair,\n\u001B[0;32m   2597\u001B[0m         add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[0;32m   2598\u001B[0m         padding\u001B[38;5;241m=\u001B[39mpadding,\n\u001B[0;32m   2599\u001B[0m         truncation\u001B[38;5;241m=\u001B[39mtruncation,\n\u001B[0;32m   2600\u001B[0m         max_length\u001B[38;5;241m=\u001B[39mmax_length,\n\u001B[0;32m   2601\u001B[0m         stride\u001B[38;5;241m=\u001B[39mstride,\n\u001B[0;32m   2602\u001B[0m         is_split_into_words\u001B[38;5;241m=\u001B[39mis_split_into_words,\n\u001B[0;32m   2603\u001B[0m         pad_to_multiple_of\u001B[38;5;241m=\u001B[39mpad_to_multiple_of,\n\u001B[0;32m   2604\u001B[0m         return_tensors\u001B[38;5;241m=\u001B[39mreturn_tensors,\n\u001B[0;32m   2605\u001B[0m         return_token_type_ids\u001B[38;5;241m=\u001B[39mreturn_token_type_ids,\n\u001B[0;32m   2606\u001B[0m         return_attention_mask\u001B[38;5;241m=\u001B[39mreturn_attention_mask,\n\u001B[0;32m   2607\u001B[0m         return_overflowing_tokens\u001B[38;5;241m=\u001B[39mreturn_overflowing_tokens,\n\u001B[0;32m   2608\u001B[0m         return_special_tokens_mask\u001B[38;5;241m=\u001B[39mreturn_special_tokens_mask,\n\u001B[0;32m   2609\u001B[0m         return_offsets_mapping\u001B[38;5;241m=\u001B[39mreturn_offsets_mapping,\n\u001B[0;32m   2610\u001B[0m         return_length\u001B[38;5;241m=\u001B[39mreturn_length,\n\u001B[0;32m   2611\u001B[0m         verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[0;32m   2612\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   2613\u001B[0m     )\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2667\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.encode_plus\u001B[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m   2657\u001B[0m \u001B[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001B[39;00m\n\u001B[0;32m   2658\u001B[0m padding_strategy, truncation_strategy, max_length, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_padding_truncation_strategies(\n\u001B[0;32m   2659\u001B[0m     padding\u001B[38;5;241m=\u001B[39mpadding,\n\u001B[0;32m   2660\u001B[0m     truncation\u001B[38;5;241m=\u001B[39mtruncation,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2664\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   2665\u001B[0m )\n\u001B[1;32m-> 2667\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_encode_plus(\n\u001B[0;32m   2668\u001B[0m     text\u001B[38;5;241m=\u001B[39mtext,\n\u001B[0;32m   2669\u001B[0m     text_pair\u001B[38;5;241m=\u001B[39mtext_pair,\n\u001B[0;32m   2670\u001B[0m     add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[0;32m   2671\u001B[0m     padding_strategy\u001B[38;5;241m=\u001B[39mpadding_strategy,\n\u001B[0;32m   2672\u001B[0m     truncation_strategy\u001B[38;5;241m=\u001B[39mtruncation_strategy,\n\u001B[0;32m   2673\u001B[0m     max_length\u001B[38;5;241m=\u001B[39mmax_length,\n\u001B[0;32m   2674\u001B[0m     stride\u001B[38;5;241m=\u001B[39mstride,\n\u001B[0;32m   2675\u001B[0m     is_split_into_words\u001B[38;5;241m=\u001B[39mis_split_into_words,\n\u001B[0;32m   2676\u001B[0m     pad_to_multiple_of\u001B[38;5;241m=\u001B[39mpad_to_multiple_of,\n\u001B[0;32m   2677\u001B[0m     return_tensors\u001B[38;5;241m=\u001B[39mreturn_tensors,\n\u001B[0;32m   2678\u001B[0m     return_token_type_ids\u001B[38;5;241m=\u001B[39mreturn_token_type_ids,\n\u001B[0;32m   2679\u001B[0m     return_attention_mask\u001B[38;5;241m=\u001B[39mreturn_attention_mask,\n\u001B[0;32m   2680\u001B[0m     return_overflowing_tokens\u001B[38;5;241m=\u001B[39mreturn_overflowing_tokens,\n\u001B[0;32m   2681\u001B[0m     return_special_tokens_mask\u001B[38;5;241m=\u001B[39mreturn_special_tokens_mask,\n\u001B[0;32m   2682\u001B[0m     return_offsets_mapping\u001B[38;5;241m=\u001B[39mreturn_offsets_mapping,\n\u001B[0;32m   2683\u001B[0m     return_length\u001B[38;5;241m=\u001B[39mreturn_length,\n\u001B[0;32m   2684\u001B[0m     verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[0;32m   2685\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   2686\u001B[0m )\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:502\u001B[0m, in \u001B[0;36mPreTrainedTokenizerFast._encode_plus\u001B[1;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m    479\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_encode_plus\u001B[39m(\n\u001B[0;32m    480\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    481\u001B[0m     text: Union[TextInput, PreTokenizedInput],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    498\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    499\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BatchEncoding:\n\u001B[0;32m    501\u001B[0m     batched_input \u001B[38;5;241m=\u001B[39m [(text, text_pair)] \u001B[38;5;28;01mif\u001B[39;00m text_pair \u001B[38;5;28;01melse\u001B[39;00m [text]\n\u001B[1;32m--> 502\u001B[0m     batched_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_encode_plus(\n\u001B[0;32m    503\u001B[0m         batched_input,\n\u001B[0;32m    504\u001B[0m         is_split_into_words\u001B[38;5;241m=\u001B[39mis_split_into_words,\n\u001B[0;32m    505\u001B[0m         add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[0;32m    506\u001B[0m         padding_strategy\u001B[38;5;241m=\u001B[39mpadding_strategy,\n\u001B[0;32m    507\u001B[0m         truncation_strategy\u001B[38;5;241m=\u001B[39mtruncation_strategy,\n\u001B[0;32m    508\u001B[0m         max_length\u001B[38;5;241m=\u001B[39mmax_length,\n\u001B[0;32m    509\u001B[0m         stride\u001B[38;5;241m=\u001B[39mstride,\n\u001B[0;32m    510\u001B[0m         pad_to_multiple_of\u001B[38;5;241m=\u001B[39mpad_to_multiple_of,\n\u001B[0;32m    511\u001B[0m         return_tensors\u001B[38;5;241m=\u001B[39mreturn_tensors,\n\u001B[0;32m    512\u001B[0m         return_token_type_ids\u001B[38;5;241m=\u001B[39mreturn_token_type_ids,\n\u001B[0;32m    513\u001B[0m         return_attention_mask\u001B[38;5;241m=\u001B[39mreturn_attention_mask,\n\u001B[0;32m    514\u001B[0m         return_overflowing_tokens\u001B[38;5;241m=\u001B[39mreturn_overflowing_tokens,\n\u001B[0;32m    515\u001B[0m         return_special_tokens_mask\u001B[38;5;241m=\u001B[39mreturn_special_tokens_mask,\n\u001B[0;32m    516\u001B[0m         return_offsets_mapping\u001B[38;5;241m=\u001B[39mreturn_offsets_mapping,\n\u001B[0;32m    517\u001B[0m         return_length\u001B[38;5;241m=\u001B[39mreturn_length,\n\u001B[0;32m    518\u001B[0m         verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[0;32m    519\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    520\u001B[0m     )\n\u001B[0;32m    522\u001B[0m     \u001B[38;5;66;03m# Return tensor is None, then we can remove the leading batch axis\u001B[39;00m\n\u001B[0;32m    523\u001B[0m     \u001B[38;5;66;03m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001B[39;00m\n\u001B[0;32m    524\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m return_tensors \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_overflowing_tokens:\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:429\u001B[0m, in \u001B[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001B[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001B[0m\n\u001B[0;32m    420\u001B[0m \u001B[38;5;66;03m# Set the truncation and padding strategy and restore the initial configuration\u001B[39;00m\n\u001B[0;32m    421\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_truncation_and_padding(\n\u001B[0;32m    422\u001B[0m     padding_strategy\u001B[38;5;241m=\u001B[39mpadding_strategy,\n\u001B[0;32m    423\u001B[0m     truncation_strategy\u001B[38;5;241m=\u001B[39mtruncation_strategy,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    426\u001B[0m     pad_to_multiple_of\u001B[38;5;241m=\u001B[39mpad_to_multiple_of,\n\u001B[0;32m    427\u001B[0m )\n\u001B[1;32m--> 429\u001B[0m encodings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode_batch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    430\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_text_or_text_pairs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    431\u001B[0m \u001B[43m    \u001B[49m\u001B[43madd_special_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madd_special_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    432\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_pretokenized\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_split_into_words\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    433\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    435\u001B[0m \u001B[38;5;66;03m# Convert encoding to dict\u001B[39;00m\n\u001B[0;32m    436\u001B[0m \u001B[38;5;66;03m# `Tokens` has type: Tuple[\u001B[39;00m\n\u001B[0;32m    437\u001B[0m \u001B[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001B[39;00m\n\u001B[0;32m    438\u001B[0m \u001B[38;5;66;03m#                       List[EncodingFast]\u001B[39;00m\n\u001B[0;32m    439\u001B[0m \u001B[38;5;66;03m#                    ]\u001B[39;00m\n\u001B[0;32m    440\u001B[0m \u001B[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001B[39;00m\n\u001B[0;32m    441\u001B[0m tokens_and_encodings \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    442\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_encoding(\n\u001B[0;32m    443\u001B[0m         encoding\u001B[38;5;241m=\u001B[39mencoding,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    452\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m encoding \u001B[38;5;129;01min\u001B[39;00m encodings\n\u001B[0;32m    453\u001B[0m ]\n",
      "\u001B[1;31mTypeError\u001B[0m: PreTokenizedEncodeInput must be Union[PreTokenizedInputSequence, Tuple[PreTokenizedInputSequence, PreTokenizedInputSequence]]"
     ]
    }
   ],
   "source": [
    "text = \"Obama was the president of the United States and he was born in Hawai.\"\n",
    "\n",
    "encoding = tokenizer(text, return_tensors=\"tf\",is_split_into_words=True)\n",
    "# forward pass\n",
    "outputs = model(**encoding)\n",
    "logits = outputs.logits\n",
    "print(logits.shape)\n",
    "predicted_label_classes = logits.argmax(-1)\n",
    "print(predicted_label_classes)\n",
    "predicted_labels = [model.config.id2label[id] for id in predicted_label_classes.squeeze().tolist()]\n",
    "print(predicted_labels)\n",
    "for id, label in zip(encoding.input_ids.squeeze().tolist(), predicted_labels):\n",
    "  print(tokenizer.decode([id]), label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'B-PER', 'O']\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = [model.config.id2label[id] for id in predicted_token_class_ids[0].numpy().tolist()]\n",
    "print(predicted_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [216], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m inputs\u001B[38;5;241m.\u001B[39mtokens:\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(i)\n",
      "\u001B[1;31mTypeError\u001B[0m: 'method' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i in inputs.tokens:\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method BatchEncoding.tokens of {'input_ids': <tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[ 102, 8668,  668,  153, 2591,  103]])>, 'token_type_ids': <tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[0, 0, 0, 0, 0, 0]])>, 'attention_mask': <tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1]])>}>"
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "EagerTensor object has no attribute 'tolist'. \n        If you are looking for numpy-related methods, please run the following:\n        from tensorflow.python.ops.numpy_ops import np_config\n        np_config.enable_numpy_behavior()\n      ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [209], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28mid\u001B[39m, label \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[43minputs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtolist\u001B[49m(), predicted_labels):\n\u001B[0;32m      2\u001B[0m   \u001B[38;5;28mprint\u001B[39m(tokenizer\u001B[38;5;241m.\u001B[39mdecode([\u001B[38;5;28mid\u001B[39m]), label)\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:440\u001B[0m, in \u001B[0;36mTensor.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    436\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getattr__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name):\n\u001B[0;32m    437\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mT\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mastype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mravel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtranspose\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreshape\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclip\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msize\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    438\u001B[0m               \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtolist\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m}:\n\u001B[0;32m    439\u001B[0m     \u001B[38;5;66;03m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001B[39;00m\n\u001B[1;32m--> 440\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[0;32m    441\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m    442\u001B[0m \u001B[38;5;124m      If you are looking for numpy-related methods, please run the following:\u001B[39m\n\u001B[0;32m    443\u001B[0m \u001B[38;5;124m      from tensorflow.python.ops.numpy_ops import np_config\u001B[39m\n\u001B[0;32m    444\u001B[0m \u001B[38;5;124m      np_config.enable_numpy_behavior()\u001B[39m\n\u001B[0;32m    445\u001B[0m \u001B[38;5;124m    \u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m)\n\u001B[0;32m    446\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getattribute__\u001B[39m(name)\n",
      "\u001B[1;31mAttributeError\u001B[0m: EagerTensor object has no attribute 'tolist'. \n        If you are looking for numpy-related methods, please run the following:\n        from tensorflow.python.ops.numpy_ops import np_config\n        np_config.enable_numpy_behavior()\n      "
     ]
    }
   ],
   "source": [
    "for id, label in zip(inputs.input_ids.tolist(), predicted_labels):\n",
    "  print(tokenizer.decode([id]), label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 102, 8668,  668,  153, 2591,  103]])"
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids.numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'ids': 'dict' object cannot be converted to 'Sequence'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [202], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3436\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.decode\u001B[1;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001B[0m\n\u001B[0;32m   3433\u001B[0m \u001B[38;5;66;03m# Convert inputs to python lists\u001B[39;00m\n\u001B[0;32m   3434\u001B[0m token_ids \u001B[38;5;241m=\u001B[39m to_py_obj(token_ids)\n\u001B[1;32m-> 3436\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decode(\n\u001B[0;32m   3437\u001B[0m     token_ids\u001B[38;5;241m=\u001B[39mtoken_ids,\n\u001B[0;32m   3438\u001B[0m     skip_special_tokens\u001B[38;5;241m=\u001B[39mskip_special_tokens,\n\u001B[0;32m   3439\u001B[0m     clean_up_tokenization_spaces\u001B[38;5;241m=\u001B[39mclean_up_tokenization_spaces,\n\u001B[0;32m   3440\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   3441\u001B[0m )\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\transformers\\tokenization_utils_fast.py:551\u001B[0m, in \u001B[0;36mPreTrainedTokenizerFast._decode\u001B[1;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001B[0m\n\u001B[0;32m    549\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(token_ids, \u001B[38;5;28mint\u001B[39m):\n\u001B[0;32m    550\u001B[0m     token_ids \u001B[38;5;241m=\u001B[39m [token_ids]\n\u001B[1;32m--> 551\u001B[0m text \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtoken_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskip_special_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskip_special_tokens\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    553\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m clean_up_tokenization_spaces:\n\u001B[0;32m    554\u001B[0m     clean_text \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclean_up_tokenization(text)\n",
      "\u001B[1;31mTypeError\u001B[0m: argument 'ids': 'dict' object cannot be converted to 'Sequence'"
     ]
    }
   ],
   "source": [
    "tokenizer.decode(inputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 39s 495ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [200], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m pred\u001B[38;5;241m=\u001B[39m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtf_train_set\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\engine\\training.py:2287\u001B[0m, in \u001B[0;36mModel.predict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   2278\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   2279\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected result of `predict_function` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2280\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(Empty batch_outputs). Please use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2284\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124missue/bug to `tf.keras`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2285\u001B[0m         )\n\u001B[0;32m   2286\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_predict_end()\n\u001B[1;32m-> 2287\u001B[0m all_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__internal__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_structure_up_to\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2288\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpotentially_ragged_concat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutputs\u001B[49m\n\u001B[0;32m   2289\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2291\u001B[0m \u001B[38;5;66;03m# If originally PSS strategy was used, then replace it back since\u001B[39;00m\n\u001B[0;32m   2292\u001B[0m \u001B[38;5;66;03m# predict is running under `OneDeviceStrategy` after the swap and once\u001B[39;00m\n\u001B[0;32m   2293\u001B[0m \u001B[38;5;66;03m# its done we need to replace it back to PSS again.\u001B[39;00m\n\u001B[0;32m   2294\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m original_pss_strategy \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:1428\u001B[0m, in \u001B[0;36mmap_structure_up_to\u001B[1;34m(shallow_tree, func, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1354\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__internal__.nest.map_structure_up_to\u001B[39m\u001B[38;5;124m\"\u001B[39m, v1\u001B[38;5;241m=\u001B[39m[])\n\u001B[0;32m   1355\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmap_structure_up_to\u001B[39m(shallow_tree, func, \u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   1356\u001B[0m   \u001B[38;5;124;03m\"\"\"Applies a function or op to a number of partially flattened inputs.\u001B[39;00m\n\u001B[0;32m   1357\u001B[0m \n\u001B[0;32m   1358\u001B[0m \u001B[38;5;124;03m  The `inputs` are flattened up to `shallow_tree` before being mapped.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1426\u001B[0m \u001B[38;5;124;03m    `shallow_tree`.\u001B[39;00m\n\u001B[0;32m   1427\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1428\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m map_structure_with_tuple_paths_up_to(\n\u001B[0;32m   1429\u001B[0m       shallow_tree,\n\u001B[0;32m   1430\u001B[0m       \u001B[38;5;28;01mlambda\u001B[39;00m _, \u001B[38;5;241m*\u001B[39mvalues: func(\u001B[38;5;241m*\u001B[39mvalues),  \u001B[38;5;66;03m# Discards the path arg.\u001B[39;00m\n\u001B[0;32m   1431\u001B[0m       \u001B[38;5;241m*\u001B[39minputs,\n\u001B[0;32m   1432\u001B[0m       \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:1528\u001B[0m, in \u001B[0;36mmap_structure_with_tuple_paths_up_to\u001B[1;34m(shallow_tree, func, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1519\u001B[0m flat_value_gen \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1520\u001B[0m     flatten_up_to(  \u001B[38;5;66;03m# pylint: disable=g-complex-comprehension\u001B[39;00m\n\u001B[0;32m   1521\u001B[0m         shallow_tree,\n\u001B[0;32m   1522\u001B[0m         input_tree,\n\u001B[0;32m   1523\u001B[0m         check_types,\n\u001B[0;32m   1524\u001B[0m         expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites) \u001B[38;5;28;01mfor\u001B[39;00m input_tree \u001B[38;5;129;01min\u001B[39;00m inputs)\n\u001B[0;32m   1525\u001B[0m flat_path_gen \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1526\u001B[0m     path\n\u001B[0;32m   1527\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m path, _ \u001B[38;5;129;01min\u001B[39;00m _yield_flat_up_to(shallow_tree, inputs[\u001B[38;5;241m0\u001B[39m], is_nested_fn))\n\u001B[1;32m-> 1528\u001B[0m results \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m   1529\u001B[0m     func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;28;01mfor\u001B[39;00m args \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(flat_path_gen, \u001B[38;5;241m*\u001B[39mflat_value_gen)\n\u001B[0;32m   1530\u001B[0m ]\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pack_sequence_as(structure\u001B[38;5;241m=\u001B[39mshallow_tree, flat_sequence\u001B[38;5;241m=\u001B[39mresults,\n\u001B[0;32m   1532\u001B[0m                         expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites)\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:1529\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m   1519\u001B[0m flat_value_gen \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1520\u001B[0m     flatten_up_to(  \u001B[38;5;66;03m# pylint: disable=g-complex-comprehension\u001B[39;00m\n\u001B[0;32m   1521\u001B[0m         shallow_tree,\n\u001B[0;32m   1522\u001B[0m         input_tree,\n\u001B[0;32m   1523\u001B[0m         check_types,\n\u001B[0;32m   1524\u001B[0m         expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites) \u001B[38;5;28;01mfor\u001B[39;00m input_tree \u001B[38;5;129;01min\u001B[39;00m inputs)\n\u001B[0;32m   1525\u001B[0m flat_path_gen \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1526\u001B[0m     path\n\u001B[0;32m   1527\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m path, _ \u001B[38;5;129;01min\u001B[39;00m _yield_flat_up_to(shallow_tree, inputs[\u001B[38;5;241m0\u001B[39m], is_nested_fn))\n\u001B[0;32m   1528\u001B[0m results \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m-> 1529\u001B[0m     func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;28;01mfor\u001B[39;00m args \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(flat_path_gen, \u001B[38;5;241m*\u001B[39mflat_value_gen)\n\u001B[0;32m   1530\u001B[0m ]\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pack_sequence_as(structure\u001B[38;5;241m=\u001B[39mshallow_tree, flat_sequence\u001B[38;5;241m=\u001B[39mresults,\n\u001B[0;32m   1532\u001B[0m                         expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites)\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:1430\u001B[0m, in \u001B[0;36mmap_structure_up_to.<locals>.<lambda>\u001B[1;34m(_, *values)\u001B[0m\n\u001B[0;32m   1354\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__internal__.nest.map_structure_up_to\u001B[39m\u001B[38;5;124m\"\u001B[39m, v1\u001B[38;5;241m=\u001B[39m[])\n\u001B[0;32m   1355\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmap_structure_up_to\u001B[39m(shallow_tree, func, \u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   1356\u001B[0m   \u001B[38;5;124;03m\"\"\"Applies a function or op to a number of partially flattened inputs.\u001B[39;00m\n\u001B[0;32m   1357\u001B[0m \n\u001B[0;32m   1358\u001B[0m \u001B[38;5;124;03m  The `inputs` are flattened up to `shallow_tree` before being mapped.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1426\u001B[0m \u001B[38;5;124;03m    `shallow_tree`.\u001B[39;00m\n\u001B[0;32m   1427\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m   1428\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m map_structure_with_tuple_paths_up_to(\n\u001B[0;32m   1429\u001B[0m       shallow_tree,\n\u001B[1;32m-> 1430\u001B[0m       \u001B[38;5;28;01mlambda\u001B[39;00m _, \u001B[38;5;241m*\u001B[39mvalues: \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m)\u001B[49m,  \u001B[38;5;66;03m# Discards the path arg.\u001B[39;00m\n\u001B[0;32m   1431\u001B[0m       \u001B[38;5;241m*\u001B[39minputs,\n\u001B[0;32m   1432\u001B[0m       \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\engine\\training.py:3849\u001B[0m, in \u001B[0;36mpotentially_ragged_concat\u001B[1;34m(tensors)\u001B[0m\n\u001B[0;32m   3847\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   3848\u001B[0m     constant_inner_shape \u001B[38;5;241m=\u001B[39m tensors[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39mconstant_inner_dimensions:]\n\u001B[1;32m-> 3849\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mragged\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstant\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3850\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43mtensor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minner_shape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconstant_inner_shape\u001B[49m\n\u001B[0;32m   3851\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mmerge_dims(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1174\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[0;32m   1175\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1176\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m dispatch_target(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[0;32m   1178\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[0;32m   1179\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[0;32m   1180\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_factory_ops.py:82\u001B[0m, in \u001B[0;36mconstant\u001B[1;34m(pylist, dtype, ragged_rank, inner_shape, name, row_splits_dtype)\u001B[0m\n\u001B[0;32m     78\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m ragged_tensor\u001B[38;5;241m.\u001B[39mRaggedTensor\u001B[38;5;241m.\u001B[39mfrom_row_splits(values, row_splits,\n\u001B[0;32m     79\u001B[0m                                                     validate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mname_scope(name, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRaggedConstant\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m---> 82\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_constant_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mragged_factory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconstant_op\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstant\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpylist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     83\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mragged_rank\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minner_shape\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_factory_ops.py:186\u001B[0m, in \u001B[0;36m_constant_value\u001B[1;34m(ragged_factory, inner_factory, pylist, dtype, ragged_rank, inner_shape)\u001B[0m\n\u001B[0;32m    182\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    183\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid ragged_rank=\u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m: must be nonnegative\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m ragged_rank)\n\u001B[0;32m    185\u001B[0m \u001B[38;5;66;03m# Find the depth of scalar values in `pylist`.\u001B[39;00m\n\u001B[1;32m--> 186\u001B[0m scalar_depth, max_depth \u001B[38;5;241m=\u001B[39m \u001B[43m_find_scalar_and_max_depth\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpylist\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    187\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m scalar_depth \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    188\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m max_depth \u001B[38;5;241m>\u001B[39m scalar_depth:\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_factory_ops.py:266\u001B[0m, in \u001B[0;36m_find_scalar_and_max_depth\u001B[1;34m(pylist)\u001B[0m\n\u001B[0;32m    264\u001B[0m max_depth \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m child \u001B[38;5;129;01min\u001B[39;00m pylist:\n\u001B[1;32m--> 266\u001B[0m   child_scalar_depth, child_max_depth \u001B[38;5;241m=\u001B[39m \u001B[43m_find_scalar_and_max_depth\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchild\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    267\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m child_scalar_depth \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    268\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m scalar_depth \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m scalar_depth \u001B[38;5;241m!=\u001B[39m child_scalar_depth \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_factory_ops.py:266\u001B[0m, in \u001B[0;36m_find_scalar_and_max_depth\u001B[1;34m(pylist)\u001B[0m\n\u001B[0;32m    264\u001B[0m max_depth \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m child \u001B[38;5;129;01min\u001B[39;00m pylist:\n\u001B[1;32m--> 266\u001B[0m   child_scalar_depth, child_max_depth \u001B[38;5;241m=\u001B[39m \u001B[43m_find_scalar_and_max_depth\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchild\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    267\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m child_scalar_depth \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    268\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m scalar_depth \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m scalar_depth \u001B[38;5;241m!=\u001B[39m child_scalar_depth \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "    \u001B[1;31m[... skipping similar frames: _find_scalar_and_max_depth at line 266 (1 times)]\u001B[0m\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_factory_ops.py:266\u001B[0m, in \u001B[0;36m_find_scalar_and_max_depth\u001B[1;34m(pylist)\u001B[0m\n\u001B[0;32m    264\u001B[0m max_depth \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m child \u001B[38;5;129;01min\u001B[39;00m pylist:\n\u001B[1;32m--> 266\u001B[0m   child_scalar_depth, child_max_depth \u001B[38;5;241m=\u001B[39m \u001B[43m_find_scalar_and_max_depth\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchild\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    267\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m child_scalar_depth \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    268\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m scalar_depth \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m scalar_depth \u001B[38;5;241m!=\u001B[39m child_scalar_depth \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\ragged\\ragged_factory_ops.py:262\u001B[0m, in \u001B[0;36m_find_scalar_and_max_depth\u001B[1;34m(pylist)\u001B[0m\n\u001B[0;32m    246\u001B[0m \u001B[38;5;124;03m\"\"\"Finds nesting depth of scalar values in pylist.\u001B[39;00m\n\u001B[0;32m    247\u001B[0m \n\u001B[0;32m    248\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    258\u001B[0m \u001B[38;5;124;03m  ValueError: If pylist has inconsistent nesting depths for scalars.\u001B[39;00m\n\u001B[0;32m    259\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    260\u001B[0m \u001B[38;5;66;03m# Check if pylist is not scalar. np.ndim builds an array, so we\u001B[39;00m\n\u001B[0;32m    261\u001B[0m \u001B[38;5;66;03m# short-circuit lists and tuples.\u001B[39;00m\n\u001B[1;32m--> 262\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(pylist, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)) \u001B[38;5;129;01mor\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mndim\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpylist\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    263\u001B[0m   scalar_depth \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    264\u001B[0m   max_depth \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36mndim\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3154\u001B[0m, in \u001B[0;36mndim\u001B[1;34m(a)\u001B[0m\n\u001B[0;32m   3123\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   3124\u001B[0m \u001B[38;5;124;03mReturn the number of dimensions of an array.\u001B[39;00m\n\u001B[0;32m   3125\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3151\u001B[0m \n\u001B[0;32m   3152\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   3153\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3154\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mndim\u001B[49m\n\u001B[0;32m   3155\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m:\n\u001B[0;32m   3156\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m asarray(a)\u001B[38;5;241m.\u001B[39mndim\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "pred=model.predict(tf_train_set)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "encoded=tokenizer(pred)\n",
    "encoded.word_ids()\n",
    "start,end=word_to_tokens(word_id)\n",
    "tokenizer.decode()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "for example in tf_train_set:\n",
    "   ainput_ids= example[0]['input_ids'].numpy()\n",
    "   atoken_type_ids= example[0]['token_type_ids'].numpy()\n",
    "   aattention_mask= example[0]['attention_mask'].numpy()\n",
    "   alabels=example[1].numpy()\n",
    "   print(example[1])\n",
    "   break\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_FLAGS\"]=\"--xla_gpu_cuda_data_dir=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.8\"\n",
    "model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'detokenizer'\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test prediction\n",
    "pred=model.predict(tf_train_set)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a=np.zeros(shape=(2))\n",
    "compute_metrics(a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list=[]\n",
    "for a in tf_train_set:\n",
    "    list.append(a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a=example[0]['input_ids'][0]\n",
    "\n",
    "tokenizer.decode(a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "\n",
    "id = 2\n",
    "\n",
    "pred_label=[]\n",
    "pred_sentence=[]\n",
    "for pred_logits in pred.logits[id]:\n",
    "    pred_sentence.append(argmax(pred_logits))\n",
    "\n",
    "print(pred_sentence)\n",
    "print(list[id][1][0].numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id=1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
