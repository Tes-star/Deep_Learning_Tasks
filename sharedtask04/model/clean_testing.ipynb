{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import data\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "df_train=pd.read_csv('../data/01_train/train.tsv', sep='\\t',\n",
    "            header=0,\n",
    "            names = [\"Nr\",\"Wort\",\"Typ1\",\"Typ2\"],\n",
    "            quoting=csv.QUOTE_NONE                     ,\n",
    "                     keep_default_na=False,\n",
    "                     encoding='utf-8')\n",
    "\n",
    "df_train = df_train.drop(df_train[df_train['Nr']=='#'].index)\n",
    "df_train=df_train.reset_index(drop=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "'Label dict filter'\n",
    "outside =0\n",
    "label_dict = {\n",
    "    'B-LOC': 2,\n",
    "    'I-LOC': 3,\n",
    "    'B-PER': 4,\n",
    "    'I-PER': 5,\n",
    "    'B-ORG': 6,\n",
    "    'I-ORG': 7,\n",
    "    'B-LOCderiv': outside,\n",
    "    \"B-LOCpart\": outside,\n",
    "    'B-ORGderiv': outside,\n",
    "    'B-ORGpart': outside,\n",
    "    'B-OTH': outside,\n",
    "    'B-OTHderiv': outside,\n",
    "    'B-OTHpart': outside,\n",
    "    'B-PERderiv': outside,\n",
    "    'B-PERpart': outside,\n",
    "    'I-LOCderiv': outside,\n",
    "    'I-LOCpart': outside,\n",
    "    'I-ORGpart': outside,\n",
    "    'I-OTH': outside,\n",
    "    'I-OTHderiv': outside,\n",
    "    'I-OTHpart': outside,\n",
    "    'I-PERderiv': outside,\n",
    "    'I-PERpart': outside,\n",
    "    'O': outside\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "tokens=[]\n",
    "labels=[]\n",
    "ids=[]\n",
    "\n",
    "sentence_token=[]\n",
    "sentence_labels=[]\n",
    "\n",
    "i=0\n",
    "\n",
    "id=0\n",
    "for j in range(0, len(df_train)):\n",
    "    if i > 0 and df_train.Nr[j] == '1':\n",
    "        tokens.append(sentence_token)\n",
    "        labels.append(sentence_labels)\n",
    "\n",
    "        sentence_token, sentence_labels = [], []\n",
    "        ids.append(id)\n",
    "        id = id + 1\n",
    "\n",
    "    sentence_token.append(str(df_train.Wort[j]))\n",
    "    # sentence_labels.append(df_train.Typ1[j])\n",
    "    sentence_labels.append(label_dict.get(df_train.Typ1[j]))\n",
    "\n",
    "    i = i + 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'Data Preprocessing'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Data Preprocessing'\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'label alignment'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'label alignment'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "conll = {'train':Dataset.from_dict({'id':ids,'tokens':tokens,'ner_tags':labels})\n",
    "    ,'validation':Dataset.from_dict({'id':ids[10:11],'tokens':tokens[10:11],'ner_tags':labels[10:11]})\n",
    "     #'test':Dataset.from_dict({'label':y_test,'text':x_test})\n",
    "     }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# from datasets import Dataset, ClassLabel, Sequence, Features, Value\n",
    "#\n",
    "# d = { 'ner_tags': labels, 'tokens': tokens}\n",
    "# # define number of tags and their names\n",
    "# tags = ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'])\n",
    "# # create dataset\n",
    "# ds ={'train':Dataset.from_dict(mapping=d, features=Features({\"ner_tags\":Sequence(tags),  'tokens': Sequence(feature=Value(dtype='string'))}))}\n",
    "# # access ClassLabel feature - 0 returns tag \"O\", 1 returns \"B-PER\" etc\n",
    "# ds['train'].features[\"ner_tags\"].feature.int2str(0)\n",
    "# #conll=ds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 0, 0, 0, 6, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['Schartau', 'sagte', 'dem', '\"', 'Tagesspiegel', '\"', 'vom', 'Freitag', ',', 'Fischer', 'sei', '\"', 'in', 'einer', 'Weise', 'aufgetreten', ',', 'die', 'alles', 'andere', 'als', 'überzeugend', 'war', '\"', '.']\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "print(conll['train'][0]['ner_tags'])\n",
    "print(conll['train'][0]['tokens'])\n",
    "\n",
    "# print(conll['train'][1]['ner_tags'])\n",
    "# print(conll['train'][1]['tokens'])\n",
    "#\n",
    "# print(conll['train'][2]['ner_tags'])\n",
    "# print(conll['train'][2]['tokens'])\n",
    "#\n",
    "# print(conll['train'][3]['ner_tags'])\n",
    "# print(conll['train'][3]['tokens'])\n",
    "#\n",
    "# print(conll['train'][4]['ner_tags'])\n",
    "# print(conll['train'][4]['tokens'])\n",
    "#\n",
    "# print(conll['train'].features['ner_tags'])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "['[CLS]',\n 'Schar',\n '##ta',\n '##u',\n 'sagte',\n 'dem',\n '\"',\n 'Tages',\n '##spiegel',\n '\"',\n 'vom',\n 'Freitag',\n ',',\n 'Fischer',\n 'sei',\n '\"',\n 'in',\n 'einer',\n 'Weise',\n 'aufgetreten',\n ',',\n 'die',\n 'alles',\n 'andere',\n 'als',\n 'überzeugen',\n '##d',\n 'war',\n '\"',\n '.',\n '[SEP]']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "'inferenz'\n",
    "model_name = 'deepset/gbert-base'\n",
    "# model_name='jplu/tf-xlm-r-ner-40-lang'\n",
    "# model_name='Davlan/bert-base-multilingual-cased-ner-hrl'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "inputs = tokenizer(conll['train'][0]['tokens'], is_split_into_words=True)\n",
    "inputs.tokens()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tokenize_and_align_labels(sequence_batch):\n",
    "    # tokenize pre-tokenized sequences\n",
    "    # long sequences will be truncated to respect the maximum token length of the language model (usually 512)\n",
    "    tokenized_sequences = tokenizer(sequence_batch['tokens'], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    # iterate over pre-tokenized tokens of single sequences\n",
    "    for i, label in enumerate(sequence_batch['ner_tags']):\n",
    "        # get associated word ids of the subtokens\n",
    "        # if a token has multiple subtokens, then each subtoken is associated with the token's word id\n",
    "        word_ids = tokenized_sequences.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        # iterate over subtokens\n",
    "        for word_idx in word_ids:\n",
    "            # special tokens (e.g. [CLS], [SEP]) get label id -100 -> loss function will ignore them\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # if the first subtoken of the next token is encountered, then associate the token's ner label with the subtoken\n",
    "            # FIXME what if two consecutive tokens are identical (e.g. \"is this a really really bad?\")?\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # consecutive subtokens will be ignored\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            # memorize the current word\n",
    "            previous_word_idx = word_idx\n",
    "        # add labels of the current sequence to the list of labels of the batch\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    # update batch labels\n",
    "    tokenized_sequences['labels'] = labels\n",
    "    return tokenized_sequences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# # test\n",
    "# example_ner_tag=conll['train'][0]['ner_tags']\n",
    "# print(example_ner_tag)\n",
    "# exampletokens=conll['train'][0]['tokens']\n",
    "# print(exampletokens)\n",
    "# example={'tokens':exampletokens,'ner_tags':example_ner_tag}\n",
    "# emaple_prepocessed=tokenize_and_align_labels(example)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['B-LOC', 'B-LOCderiv', 'B-LOCpart', 'B-ORG', 'B-ORGderiv',\n       'B-ORGpart', 'B-OTH', 'B-OTHderiv', 'B-OTHpart', 'B-PER',\n       'B-PERderiv', 'B-PERpart', 'I-LOC', 'I-LOCderiv', 'I-LOCpart',\n       'I-ORG', 'I-ORGpart', 'I-OTH', 'I-OTHderiv', 'I-OTHpart', 'I-PER',\n       'I-PERderiv', 'I-PERpart', 'O'], dtype=object)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import unique\n",
    "\n",
    "unique(df_train.Typ1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# tf_train_set = model.prepare_tf_dataset(\n",
    "#     conll['train'].map(tokenize_and_align_labels, batched=True),\n",
    "#     shuffle=True,\n",
    "#     batch_size=1,\n",
    "#     collate_fn=data_collator,\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#conll['train'][0]['pos_tags']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#conll['train'].features['pos_tags']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from keras.losses import BinaryCrossentropy, CategoricalCrossentropy, SparseCategoricalCrossentropy, Hinge\n",
    "from transformers import TFAutoModelForTokenClassification, create_optimizer\n",
    "\n",
    "'LMtraining'\n",
    "\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(model_name, num_labels=8)\n",
    "batch_size = 32\n",
    "num_train_epochs = 30\n",
    "num_train_steps = (len(conll['train']) // batch_size) * num_train_epochs\n",
    "# optimizer, lr_schedule = create_optimizer(\n",
    "#     init_lr=2e-5,\n",
    "#     num_train_steps=num_train_steps,\n",
    "#     weight_decay_rate=0.01,\n",
    "#     num_warmup_steps=0,\n",
    "# )\n",
    "\n",
    "model.get_layer('bert').trainable=False\n",
    "#SparseCategoricalCrossentropy(from_logits=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\",  metrics=[\"accuracy\"])\n",
    "#model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2125ef22f712470292a5173cbb37a1c1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Timo\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:715: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ebcdd53c4c1e4f98b3957523cec9f3f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, return_tensors=\"tf\")\n",
    "tf_train_set = model.prepare_tf_dataset(\n",
    "    conll['train'].map(tokenize_and_align_labels, batched=True),\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_validation_set = model.prepare_tf_dataset(\n",
    "    conll['validation'].map(tokenize_and_align_labels, batched=True),\n",
    "    shuffle=True,\n",
    "    batch_size=1,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Timo\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:715: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.3459"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Predictions and/or references don't match the expected format.\nExpected format: {'predictions': Sequence(feature=Value(dtype='string', id='label'), length=-1, id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='label'), length=-1, id='sequence')},\nInput predictions: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\nInput references: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [37], line 39\u001B[0m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m     38\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mXLA_FLAGS\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--xla_gpu_cuda_data_dir=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.8\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 39\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtf_train_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtf_validation_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mmetric_callback\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\transformers\\keras_callbacks.py:255\u001B[0m, in \u001B[0;36mKerasMetricCallback.on_epoch_end\u001B[1;34m(self, epoch, logs)\u001B[0m\n\u001B[0;32m    252\u001B[0m all_preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_postprocess_predictions_or_labels(prediction_list)\n\u001B[0;32m    253\u001B[0m all_labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_postprocess_predictions_or_labels(label_list)\n\u001B[1;32m--> 255\u001B[0m metric_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmetric_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mall_preds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mall_labels\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    256\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(metric_output, \u001B[38;5;28mdict\u001B[39m):\n\u001B[0;32m    257\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    258\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetric_fn should return a dict mapping metric names to values but instead returned \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_output\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    259\u001B[0m     )\n",
      "Cell \u001B[1;32mIn [37], line 23\u001B[0m, in \u001B[0;36mcompute_metrics\u001B[1;34m(p)\u001B[0m\n\u001B[0;32m     14\u001B[0m true_predictions \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     15\u001B[0m     [label_list[p] \u001B[38;5;28;01mfor\u001B[39;00m (p, l) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(prediction, label) \u001B[38;5;28;01mif\u001B[39;00m l \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m100\u001B[39m]\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m prediction, label \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(predictions, labels)\n\u001B[0;32m     17\u001B[0m ]\n\u001B[0;32m     18\u001B[0m true_labels \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     19\u001B[0m     [label_list[l] \u001B[38;5;28;01mfor\u001B[39;00m (p, l) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(prediction, label) \u001B[38;5;28;01mif\u001B[39;00m l \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m100\u001B[39m]\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m prediction, label \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(predictions, labels)\n\u001B[0;32m     21\u001B[0m ]\n\u001B[1;32m---> 23\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mseqeval\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrue_predictions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreferences\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrue_labels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprecision\u001B[39m\u001B[38;5;124m\"\u001B[39m: results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moverall_precision\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrecall\u001B[39m\u001B[38;5;124m\"\u001B[39m: results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moverall_recall\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mf1\u001B[39m\u001B[38;5;124m\"\u001B[39m: results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moverall_f1\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     28\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m: results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moverall_accuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     29\u001B[0m }\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\evaluate\\module.py:432\u001B[0m, in \u001B[0;36mEvaluationModule.compute\u001B[1;34m(self, predictions, references, **kwargs)\u001B[0m\n\u001B[0;32m    429\u001B[0m compute_kwargs \u001B[38;5;241m=\u001B[39m {k: kwargs[k] \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m kwargs \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_feature_names()}\n\u001B[0;32m    431\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(v \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m inputs\u001B[38;5;241m.\u001B[39mvalues()):\n\u001B[1;32m--> 432\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_batch(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs)\n\u001B[0;32m    433\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_finalize()\n\u001B[0;32m    435\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcache_file_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\evaluate\\module.py:512\u001B[0m, in \u001B[0;36mEvaluationModule.add_batch\u001B[1;34m(self, predictions, references, **kwargs)\u001B[0m\n\u001B[0;32m    505\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    506\u001B[0m     error_msg \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    507\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPredictions and/or references don\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt match the expected format.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    508\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected format: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mselected_feature_format \u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m,\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    509\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInput predictions: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msummarize_if_long_list(predictions)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m,\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    510\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInput references: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msummarize_if_long_list(references)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    511\u001B[0m     )\n\u001B[1;32m--> 512\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(error_msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
      "\u001B[1;31mValueError\u001B[0m: Predictions and/or references don't match the expected format.\nExpected format: {'predictions': Sequence(feature=Value(dtype='string', id='label'), length=-1, id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='label'), length=-1, id='sequence')},\nInput predictions: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\nInput references: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    import evaluate\n",
    "    label_list = [0,1,2,3,4,5,6,7]\n",
    "#    label_list = tf_train_set.features[f\"ner_tags\"].feature.names\n",
    "\n",
    "    seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "\n",
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set)\n",
    "model.compile(optimizer=\"adam\",  # loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "#model.summary()\n",
    "import os\n",
    "os.environ[\"XLA_FLAGS\"]=\"--xla_gpu_cuda_data_dir=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.8\"\n",
    "model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=30,callbacks=[metric_callback])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "for example in tf_train_set:\n",
    "   ainput_ids= example[0]['input_ids'].numpy()\n",
    "   atoken_type_ids= example[0]['token_type_ids'].numpy()\n",
    "   aattention_mask= example[0]['attention_mask'].numpy()\n",
    "   alabels=example[1].numpy()\n",
    "   print(example[1])\n",
    "   break\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Timo\\PycharmProjects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:715: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 67s 79ms/step - loss: 0.1139 - accuracy: 0.3421 - val_loss: 9.1680e-04 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x2a594b4a580>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"XLA_FLAGS\"]=\"--xla_gpu_cuda_data_dir=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.8\"\n",
    "model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'detokenizer'\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 55s 71ms/step\n"
     ]
    }
   ],
   "source": [
    "# test prediction\n",
    "pred=model.predict(tf_train_set)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [34], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mcompute_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpred\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn [28], line 11\u001B[0m, in \u001B[0;36mcompute_metrics\u001B[1;34m(p)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m#    label_list = tf_train_set.features[f\"ner_tags\"].feature.names\u001B[39;00m\n\u001B[0;32m      9\u001B[0m     seqeval \u001B[38;5;241m=\u001B[39m evaluate\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseqeval\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 11\u001B[0m     predictions, labels \u001B[38;5;241m=\u001B[39m p\n\u001B[0;32m     12\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(predictions, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     14\u001B[0m     true_predictions \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     15\u001B[0m         [label_list[p] \u001B[38;5;28;01mfor\u001B[39;00m (p, l) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(prediction, label) \u001B[38;5;28;01mif\u001B[39;00m l \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m100\u001B[39m]\n\u001B[0;32m     16\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m prediction, label \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(predictions, labels)\n\u001B[0;32m     17\u001B[0m     ]\n",
      "\u001B[1;31mValueError\u001B[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "te\n",
    "compute_metrics(pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list=[]\n",
    "for a in tf_train_set:\n",
    "    list.append(a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a=example[0]['input_ids'][0]\n",
    "\n",
    "tokenizer.decode(a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "\n",
    "id = 2\n",
    "\n",
    "pred_label=[]\n",
    "pred_sentence=[]\n",
    "for pred_logits in pred.logits[id]:\n",
    "    pred_sentence.append(argmax(pred_logits))\n",
    "\n",
    "print(pred_sentence)\n",
    "print(list[id][1][0].numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id=1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
