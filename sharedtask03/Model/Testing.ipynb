{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "import numpy  as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.metrics import Precision, Recall\n",
    "\n",
    "import operator\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "import segmentation_models as sm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import wandb\n",
    "from numpy import float16\n",
    "from segmentation_models import Unet\n",
    "from wandb.integration.keras import WandbCallback\n",
    "import keras\n",
    "# or from tensorflow import keras\n",
    "\n",
    "keras.backend.set_image_data_format('channels_last')\n",
    "# or keras.backend.set_image_data_format('channels_first')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airplane\n",
      "automobile\n",
      "bird\n",
      "cat\n",
      "deer\n",
      "dog\n",
      "horse\n",
      "ship\n",
      "truck\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sharedtask03.Model.helper import import_images\n",
    "images=[]\n",
    "\n",
    "path = '../data/01_train/train/'\n",
    "folders = os.listdir(path)\n",
    "i=True\n",
    "for folder in folders:\n",
    "    y_train,x_train=import_images(path+folder+'/')\n",
    "    print(folder)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "x_train = tf.convert_to_tensor(x_train, dtype=float16)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=float16)\n",
    "# x_test = tf.convert_to_tensor(x_test, dtype=float16)\n",
    "# y_test = tf.convert_to_tensor(y_test, dtype=float16)\n",
    "\n",
    "# define number of channels\n",
    "N = x_train.shape[-1]\n",
    "\n",
    "# define model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 32, 32, 3)   12          ['input_5[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 32, 32, 64)   1792        ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_58 (ReLU)                (None, 32, 32, 64)   0           ['conv2d_64[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 32, 32, 64)  256         ['re_lu_58[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 32, 32, 64)   36928       ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_59 (ReLU)                (None, 32, 32, 64)   0           ['conv2d_65[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 32, 32, 64)  256         ['re_lu_59[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 32, 32, 64)   36928       ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, 32, 32, 64)   0           ['batch_normalization_61[0][0]', \n",
      "                                                                  'conv2d_66[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_60 (ReLU)                (None, 32, 32, 64)   0           ['add_28[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 32, 32, 64)  256         ['re_lu_60[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 32, 32, 64)   36928       ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_61 (ReLU)                (None, 32, 32, 64)   0           ['conv2d_67[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 32, 32, 64)  256         ['re_lu_61[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 32, 32, 64)   36928       ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, 32, 32, 64)   0           ['batch_normalization_63[0][0]', \n",
      "                                                                  'conv2d_68[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_62 (ReLU)                (None, 32, 32, 64)   0           ['add_29[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 32, 32, 64)  256         ['re_lu_62[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 16, 16, 128)  73856       ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_63 (ReLU)                (None, 16, 16, 128)  0           ['conv2d_69[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 16, 16, 128)  512        ['re_lu_63[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 16, 16, 128)  8320        ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 16, 16, 128)  147584      ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " add_30 (Add)                   (None, 16, 16, 128)  0           ['conv2d_71[0][0]',              \n",
      "                                                                  'conv2d_70[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_64 (ReLU)                (None, 16, 16, 128)  0           ['add_30[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 16, 16, 128)  512        ['re_lu_64[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 16, 16, 128)  147584      ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_65 (ReLU)                (None, 16, 16, 128)  0           ['conv2d_72[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 16, 16, 128)  512        ['re_lu_65[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 16, 16, 128)  147584      ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " add_31 (Add)                   (None, 16, 16, 128)  0           ['batch_normalization_67[0][0]', \n",
      "                                                                  'conv2d_73[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_66 (ReLU)                (None, 16, 16, 128)  0           ['add_31[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 16, 16, 128)  512        ['re_lu_66[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 16, 16, 128)  147584      ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_67 (ReLU)                (None, 16, 16, 128)  0           ['conv2d_74[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 16, 16, 128)  512        ['re_lu_67[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 16, 16, 128)  147584      ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " add_32 (Add)                   (None, 16, 16, 128)  0           ['batch_normalization_69[0][0]', \n",
      "                                                                  'conv2d_75[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_68 (ReLU)                (None, 16, 16, 128)  0           ['add_32[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 16, 16, 128)  512        ['re_lu_68[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 16, 16, 128)  147584      ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_69 (ReLU)                (None, 16, 16, 128)  0           ['conv2d_76[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 16, 16, 128)  512        ['re_lu_69[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 16, 16, 128)  147584      ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " add_33 (Add)                   (None, 16, 16, 128)  0           ['batch_normalization_71[0][0]', \n",
      "                                                                  'conv2d_77[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_70 (ReLU)                (None, 16, 16, 128)  0           ['add_33[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 16, 16, 128)  512        ['re_lu_70[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 16, 16, 128)  147584      ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_71 (ReLU)                (None, 16, 16, 128)  0           ['conv2d_78[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 16, 16, 128)  512        ['re_lu_71[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 16, 16, 128)  147584      ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " add_34 (Add)                   (None, 16, 16, 128)  0           ['batch_normalization_73[0][0]', \n",
      "                                                                  'conv2d_79[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_72 (ReLU)                (None, 16, 16, 128)  0           ['add_34[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 16, 16, 128)  512        ['re_lu_72[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 8, 8, 256)    295168      ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_73 (ReLU)                (None, 8, 8, 256)    0           ['conv2d_80[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 8, 8, 256)   1024        ['re_lu_73[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 8, 8, 256)    33024       ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 8, 8, 256)    590080      ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " add_35 (Add)                   (None, 8, 8, 256)    0           ['conv2d_82[0][0]',              \n",
      "                                                                  'conv2d_81[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_74 (ReLU)                (None, 8, 8, 256)    0           ['add_35[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 8, 8, 256)   1024        ['re_lu_74[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 8, 8, 256)    590080      ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_75 (ReLU)                (None, 8, 8, 256)    0           ['conv2d_83[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 8, 8, 256)   1024        ['re_lu_75[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 8, 8, 256)    590080      ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " add_36 (Add)                   (None, 8, 8, 256)    0           ['batch_normalization_77[0][0]', \n",
      "                                                                  'conv2d_84[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_76 (ReLU)                (None, 8, 8, 256)    0           ['add_36[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 8, 8, 256)   1024        ['re_lu_76[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 8, 8, 256)    590080      ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_77 (ReLU)                (None, 8, 8, 256)    0           ['conv2d_85[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 8, 8, 256)   1024        ['re_lu_77[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 8, 8, 256)    590080      ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " add_37 (Add)                   (None, 8, 8, 256)    0           ['batch_normalization_79[0][0]', \n",
      "                                                                  'conv2d_86[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_78 (ReLU)                (None, 8, 8, 256)    0           ['add_37[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 8, 8, 256)   1024        ['re_lu_78[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 8, 8, 256)    590080      ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_79 (ReLU)                (None, 8, 8, 256)    0           ['conv2d_87[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 8, 8, 256)   1024        ['re_lu_79[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 8, 8, 256)    590080      ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " add_38 (Add)                   (None, 8, 8, 256)    0           ['batch_normalization_81[0][0]', \n",
      "                                                                  'conv2d_88[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_80 (ReLU)                (None, 8, 8, 256)    0           ['add_38[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 8, 8, 256)   1024        ['re_lu_80[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 8, 8, 256)    590080      ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_81 (ReLU)                (None, 8, 8, 256)    0           ['conv2d_89[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 8, 8, 256)   1024        ['re_lu_81[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 8, 8, 256)    590080      ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " add_39 (Add)                   (None, 8, 8, 256)    0           ['batch_normalization_83[0][0]', \n",
      "                                                                  'conv2d_90[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_82 (ReLU)                (None, 8, 8, 256)    0           ['add_39[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 8, 8, 256)   1024        ['re_lu_82[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 4, 4, 512)    1180160     ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_83 (ReLU)                (None, 4, 4, 512)    0           ['conv2d_91[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 4, 4, 512)   2048        ['re_lu_83[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 4, 4, 512)    131584      ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 4, 4, 512)    2359808     ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " add_40 (Add)                   (None, 4, 4, 512)    0           ['conv2d_93[0][0]',              \n",
      "                                                                  'conv2d_92[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_84 (ReLU)                (None, 4, 4, 512)    0           ['add_40[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 4, 4, 512)   2048        ['re_lu_84[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)             (None, 4, 4, 512)    2359808     ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_85 (ReLU)                (None, 4, 4, 512)    0           ['conv2d_94[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 4, 4, 512)   2048        ['re_lu_85[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)             (None, 4, 4, 512)    2359808     ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " add_41 (Add)                   (None, 4, 4, 512)    0           ['batch_normalization_87[0][0]', \n",
      "                                                                  'conv2d_95[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_86 (ReLU)                (None, 4, 4, 512)    0           ['add_41[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 4, 4, 512)   2048        ['re_lu_86[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 1, 1, 512)   0           ['batch_normalization_89[0][0]'] \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 512)          0           ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 10)           5130        ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 15,619,990\n",
      "Trainable params: 15,607,568\n",
      "Non-trainable params: 12,422\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sharedtask03.Model.Model_imported import create_res_net\n",
    "from segmentation_models.losses import DiceLoss\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = create_res_net() # or create_plain_net()\n",
    "model.summary()\n",
    "# save model after each epoch\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath='ModelCheckpoint/',\n",
    "    verbose=1\n",
    ")\n",
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir='tensorboard_logs/',\n",
    "    histogram_freq=1\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45000 files belonging to 9 classes.\n",
      "Using 22500 files for training.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = '../data/01_train/train/'\n",
    "train_ds = keras.utils.image_dataset_from_directory(path,\n",
    "                                                    image_size=(32, 32),\n",
    "                                                    color_mode='rgb',\n",
    "                                                    seed=1234\n",
    "                                                    ,validation_split=0.5\n",
    "                                                    ,subset='training',\n",
    "                                                     labels='inferred',\n",
    "                                                    label_mode='categorical')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dense, Input, Flatten, Dropout, Embedding, Conv2D\n",
    "from keras.layers import MaxPool2D\n",
    "\n",
    "from keras.layers import UpSampling2D\n",
    "\n",
    "\n",
    "def get_model():\n",
    "        # input in the shape of a single digit\n",
    "    input = keras.Input((32, 32,3))\n",
    "    # reshape to match requirements of convolutional layer: (None, 28, 28) -> (None, 28, 28, 1)\n",
    "    #expanded_input=tf.expand_dims(input, axis=-1)\n",
    "\n",
    "    # Block 1: (None, 28, 28, 1) -> (None, 14, 14, 4)\n",
    "    conv_1 = keras.layers.Conv2D(filters=4, kernel_size=3, padding='same')(input)\n",
    "    conv_2 = keras.layers.Conv2D(filters=4, kernel_size=3, padding='same')(conv_1)\n",
    "    max_pool_1 = keras.layers.MaxPool2D()(conv_2)\n",
    "\n",
    "    # Block 2: (None, 14, 14, 4) -> (None, 7, 7, 4)\n",
    "    conv_3 = keras.layers.Conv2D(filters=4, kernel_size=3,  padding='same')(max_pool_1)\n",
    "    conv_4 = keras.layers.Conv2D(filters=4, kernel_size=3,  padding='same')(conv_3)\n",
    "    # Residual connection\n",
    "    res_1 = keras.layers.Add()([max_pool_1, conv_4])\n",
    "    max_pool_2 = keras.layers.MaxPool2D()(res_1)\n",
    "\n",
    "    # Block 3: (None, 7, 7, 4) -> (None, 7, 7, 4)\n",
    "    conv_5 = keras.layers.Conv2D(filters=4, kernel_size=3,  padding='same')(max_pool_2)\n",
    "    conv_6 = keras.layers.Conv2D(filters=4, kernel_size=3,  padding='same')(conv_5)\n",
    "    # Residual connection\n",
    "    res_2 = keras.layers.Add()([max_pool_2, conv_6])\n",
    "\n",
    "    # (None, 7, 7, 4) -> (None, 5, 5, 8)\n",
    "    conv_7 = keras.layers.Conv2D(filters=4, kernel_size=3, )(res_2)\n",
    "    # (None, 5, 5, 8) -> (None, 3, 3, 16)\n",
    "    conv_8 = keras.layers.Conv2D(filters=4, kernel_size=3, )(conv_7)\n",
    "    # (None, 3, 3, 16) -> (None, 1, 1, 16)\n",
    "    conv_9 = keras.layers.Conv2D(filters=4, kernel_size=3, )(conv_8)\n",
    "\n",
    "    # flatten input into a single dimension: (None, 1, 1, 16) -> (None, 16)\n",
    "    flat = keras.layers.Flatten()(conv_9)\n",
    "\n",
    "    # apply dense layer for classification: (None, 16) -> (None, 10)\n",
    "    output = keras.layers.Dense(units=9, activation='softmax')(flat)\n",
    "    # build and compile model\n",
    "    model = keras.Model(input, output)\n",
    "    return model\n",
    "\n",
    "#model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 704\n",
      "Epoch 1/100\n",
      "704/704 [==============================] - 24s 31ms/step - loss: 5.1013 - categorical_accuracy: 0.2612\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 22s 31ms/step - loss: 1.6822 - categorical_accuracy: 0.3707\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - 23s 32ms/step - loss: 1.6092 - categorical_accuracy: 0.4016\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - 23s 32ms/step - loss: 1.5473 - categorical_accuracy: 0.4247\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - 22s 31ms/step - loss: 1.4883 - categorical_accuracy: 0.4535\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - 21s 29ms/step - loss: 1.4545 - categorical_accuracy: 0.4677\n",
      "Epoch 7/100\n",
      "704/704 [==============================] - 21s 30ms/step - loss: 1.4332 - categorical_accuracy: 0.4747\n",
      "Epoch 8/100\n",
      "704/704 [==============================] - 23s 32ms/step - loss: 1.4160 - categorical_accuracy: 0.4827\n",
      "Epoch 9/100\n",
      "704/704 [==============================] - 22s 32ms/step - loss: 1.4039 - categorical_accuracy: 0.4900\n",
      "Epoch 10/100\n",
      "610/704 [========================>.....] - ETA: 2s - loss: 1.3945 - categorical_accuracy: 0.4982"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = get_model()\n",
    "#model.summary()\n",
    "print('Number of training batches: %d' % tf.data.experimental.cardinality(train_ds).numpy())\n",
    "\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['categorical_accuracy'])\n",
    "\n",
    "model.fit(train_ds,batch_size=100,epochs=100\n",
    "          #,\n",
    "          #validation_data=(train_2D_x[1000:],train_2D_y[1000:])\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "\n",
    "def get_simpel_model():\n",
    "        # input in the shape of a single digit\n",
    "    input = keras.Input((32, 32,3))\n",
    "    flat = keras.layers.Flatten()(input)\n",
    "    # reshape to match requirements of convolutional layer: (None, 28, 28) -> (None, 28, 28, 1)\n",
    "    #expanded_input=tf.expand_dims(input, axis=-1)\n",
    "    # apply dense layer for classification: (None, 16) -> (None, 10)\n",
    "    output = keras.layers.Dense(units=1, activation='softmax')(flat)\n",
    "    # build and compile model\n",
    "    model = keras.Model(input, output)\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_45 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 1)                 3073      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,073\n",
      "Trainable params: 3,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Number of training batches: 704\n",
      "Epoch 1/100\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - 5s 7ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "124/704 [====>.........................] - ETA: 4s - loss: 0.0000e+00 - categorical_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = get_simpel_model()\n",
    "model.summary()\n",
    "print('Number of training batches: %d' % tf.data.experimental.cardinality(train_ds).numpy())\n",
    "\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['categorical_accuracy'])\n",
    "\n",
    "model.fit(train_ds,batch_size=9,epochs=100\n",
    "          #,\n",
    "          #validation_data=(train_2D_x[1000:],train_2D_y[1000:])\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [51], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m labels \u001B[38;5;241m=\u001B[39m  np\u001B[38;5;241m.\u001B[39marray([])\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x, y \u001B[38;5;129;01min\u001B[39;00m train_ds:\n\u001B[1;32m----> 4\u001B[0m   predictions \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate([predictions, \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_classes\u001B[49m(x)])\n\u001B[0;32m      5\u001B[0m   labels \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate([labels, np\u001B[38;5;241m.\u001B[39margmax(y\u001B[38;5;241m.\u001B[39mnumpy(), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)])\n\u001B[0;32m      7\u001B[0m tf\u001B[38;5;241m.\u001B[39mmath\u001B[38;5;241m.\u001B[39mconfusion_matrix(labels\u001B[38;5;241m=\u001B[39mlabels, predictions\u001B[38;5;241m=\u001B[39mpredictions)\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Functional' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = np.array([])\n",
    "labels =  np.array([])\n",
    "for x, y in train_ds:\n",
    "  predictions = np.concatenate([predictions, model.predict_classes(x)])\n",
    "  labels = np.concatenate([labels, np.argmax(y.numpy(), axis=-1)])\n",
    "\n",
    "tf.math.confusion_matrix(labels=labels, predictions=predictions).numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.metrics import MeanIoU, OneHotMeanIoU\n",
    "#from sklearn.metrics import recall_score, f1_score, precision_score\n",
    "from keras import metrics\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001),\n",
    "              metrics = ['accuracy','categorical_accuracy',OneHotMeanIoU (num_classes=5)\n",
    "                                   ]\n",
    "              # metrics = ['accuracy','sparse_categorical_accuracy','categorical_accuracy','categorical_crossentropy',#MeanIoU(num_classes=5)\n",
    "              #                     ]\n",
    "              )\n",
    "\n",
    "#tf.keras.metrics.MeanIoU(num_classes=2)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_model:\n",
    "    input = Input(shape=(32,32,3))\n",
    "    norm1 = BatchNormalization()(input)\n",
    "\n",
    "    irnn = component_loop(norm1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"C:\\Program Files\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 978, in launch_instance\n      app.start()\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 595, in run_forever\n      self._run_once()\n    File \"C:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 1881, in _run_once\n      handle._run()\n    File \"C:\\Program Files\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\vdwti\\AppData\\Local\\Temp\\ipykernel_12968\\1428331143.py\", line 1, in <module>\n      model.fit(\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\wandb\\integration\\keras\\keras.py\", line 174, in new_v2\n      return old_v2(*args, **kwargs)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\wandb\\integration\\keras\\keras.py\", line 174, in new_v2\n      return old_v2(*args, **kwargs)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\wandb\\integration\\keras\\keras.py\", line 174, in new_v2\n      return old_v2(*args, **kwargs)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n      return self.compiled_loss(\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\losses.py\", line 272, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\losses.py\", line 2084, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\backend.py\", line 5630, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nReceived a label value of 4992 which is outside the valid range of [0, 10).  Label values: 2045 2866 2268 3316 4440 789 3172 1351 269 2646 1164 1780 2168 1895 4668 676 2580 3612 4944 1783 3944 3532 4784 1459 3600 408 2546 4 2742 4960 765 4344 3200 1655 2726 1042 2892 3496 3908 4744 2338 4540 4484 4804 2902 1882 162 4660 1349 4024 1719 1908 4028 3104 2732 224 3808 942 1531 4380 923 1744 2918 529 1809 4776 4208 4780 582 3316 3564 3726 1136 3284 2496 3136 2088 4992 4120 462 3792 4592 1967 3080 1580 2080 4528 3468 2198 2136 303 4272 1398 4050 519 3824 4600 2520 4384 2802 2468 2888 2466 3810 1525 2316 297 3392 4384 1756 184 2916 869 3960 4264 3698 3254 2284 172 1521 3020 3776 4424 2600 3052 2404 3516 4756\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_37994]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [9], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m#validation_data=(x_test, y_test),\u001B[39;49;00m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m#callbacks=[cp_callback, tensorboard_callback]\u001B[39;49;00m\n\u001B[0;32m      9\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\wandb\\integration\\keras\\keras.py:174\u001B[0m, in \u001B[0;36mpatch_tf_keras.<locals>.new_v2\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    172\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m cbk \u001B[38;5;129;01min\u001B[39;00m cbks:\n\u001B[0;32m    173\u001B[0m         set_wandb_attrs(cbk, val_data)\n\u001B[1;32m--> 174\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m old_v2(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mc:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\wandb\\integration\\keras\\keras.py:174\u001B[0m, in \u001B[0;36mpatch_tf_keras.<locals>.new_v2\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    172\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m cbk \u001B[38;5;129;01min\u001B[39;00m cbks:\n\u001B[0;32m    173\u001B[0m         set_wandb_attrs(cbk, val_data)\n\u001B[1;32m--> 174\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m old_v2(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mc:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\wandb\\integration\\keras\\keras.py:174\u001B[0m, in \u001B[0;36mpatch_tf_keras.<locals>.new_v2\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    172\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m cbk \u001B[38;5;129;01min\u001B[39;00m cbks:\n\u001B[0;32m    173\u001B[0m         set_wandb_attrs(cbk, val_data)\n\u001B[1;32m--> 174\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m old_v2(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mc:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mc:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"C:\\Program Files\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 978, in launch_instance\n      app.start()\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 595, in run_forever\n      self._run_once()\n    File \"C:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 1881, in _run_once\n      handle._run()\n    File \"C:\\Program Files\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\vdwti\\AppData\\Local\\Temp\\ipykernel_12968\\1428331143.py\", line 1, in <module>\n      model.fit(\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\wandb\\integration\\keras\\keras.py\", line 174, in new_v2\n      return old_v2(*args, **kwargs)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\wandb\\integration\\keras\\keras.py\", line 174, in new_v2\n      return old_v2(*args, **kwargs)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\wandb\\integration\\keras\\keras.py\", line 174, in new_v2\n      return old_v2(*args, **kwargs)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n      return self.compiled_loss(\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\losses.py\", line 272, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\losses.py\", line 2084, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"c:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\backend.py\", line 5630, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nReceived a label value of 4992 which is outside the valid range of [0, 10).  Label values: 2045 2866 2268 3316 4440 789 3172 1351 269 2646 1164 1780 2168 1895 4668 676 2580 3612 4944 1783 3944 3532 4784 1459 3600 408 2546 4 2742 4960 765 4344 3200 1655 2726 1042 2892 3496 3908 4744 2338 4540 4484 4804 2902 1882 162 4660 1349 4024 1719 1908 4028 3104 2732 224 3808 942 1531 4380 923 1744 2918 529 1809 4776 4208 4780 582 3316 3564 3726 1136 3284 2496 3136 2088 4992 4120 462 3792 4592 1967 3080 1580 2080 4528 3468 2198 2136 303 4272 1398 4050 519 3824 4600 2520 4384 2802 2468 2888 2466 3810 1525 2316 297 3392 4384 1756 184 2916 869 3960 4264 3698 3254 2284 172 1521 3020 3776 4424 2600 3052 2404 3516 4756\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_37994]"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    "    #validation_data=(x_test, y_test),\n",
    "    batch_size=128,\n",
    "    #callbacks=[cp_callback, tensorboard_callback]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Configs\n",
    "batch_size = 17\n",
    "epochs = 300\n",
    "metrics = ['categorical_accuracy']\n",
    "label_mapping = 'Ohne_Auto_See'  # Alternative:'Grnflchen'\n",
    "\n",
    "match label_mapping:\n",
    "    case 'Ohne_Auto_See':\n",
    "        # labels = {0: 'None', 1: 'Wiese', 2: 'Strae', 3: 'Schienen', 4: 'Haus', 5: 'Wald'}\n",
    "        labels = ['None', 'Wiese', 'Strae', 'Schienen', 'Haus', 'Wald']\n",
    "    case 'Grnflchen':\n",
    "        # labels = {0: 'None', 1: 'Grnflchen', 2: 'Strae', 3: 'Schienen', 4: 'Haus'}\n",
    "        labels = ['None', 'Grnflchen', 'Strae', 'Schienen', 'Haus']\n",
    "    case _:  # else\n",
    "        labels = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "\"\"\" wird aktuell nicht mehr bentigt. Bitte stehen lassen\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def cnn_sweep():\n",
    "    wandb.init()\n",
    "    # Access all hyperparameter values through wandb.config\n",
    "    config = wandb.config\n",
    "    # set configs\n",
    "    optim = tf.keras.optimizers.Adam(config.learning_rate)\n",
    "\n",
    "    loss = JaccardLoss()  # to avoid errors\n",
    "    match config.loss:\n",
    "        case 'JaccardLoss':\n",
    "            loss = JaccardLoss()\n",
    "        case 'DiceLoss':\n",
    "            loss = DiceLoss()\n",
    "        case 'CategoricalCrossentropy':\n",
    "            loss = CategoricalCrossentropy()\n",
    "\n",
    "    \"\"\"wird aktuell nicht mehr bentigt. Bitte stehen lassen\n",
    "    import wandb\n",
    "    # login\n",
    "    run = wandb.init(project=\"cnn_segmentation_models\", entity=\"pds_project\", name='segmentation_models_Unet',\n",
    "                     )\n",
    "    run.config.update({\"epochs\": epochs, \"batch_size\": batch_size, 'metrics': metrics, 'loss': loss, 'optim': optim,\n",
    "                       'learning_rate': learning_rate,\n",
    "                       'backbone_name': backbone_name,\n",
    "                       'activation': activation,\n",
    "                       'encoder_freeze': encoder_freeze,\n",
    "                       'augmentation': augmentation\n",
    "                       })\n",
    "    run.config.update({'images_train': len(x_train_data),\n",
    "                       'images_test': len(x_test_data),\n",
    "                       })\n",
    "    \"\"\"\n",
    "    # wandb.log({\"label_mapping\": str(label_mapping)})\n",
    "\n",
    "    # Choose bands\n",
    "    bands = list(range(0, 104, config.band_dist))\n",
    "    bands.append(105)\n",
    "    bands.append(106)\n",
    "    bands.append(107)\n",
    "    bands.append(108)\n",
    "\n",
    "    # import Data\n",
    "    x, y = import_labeled_photos(bands=bands, label_mapping=label_mapping)\n",
    "\n",
    "    x_train = x[0:22]\n",
    "    x_train.append(x[29:])\n",
    "    y_train = y[0:22]\n",
    "    y_train.append(y[29:])\n",
    "\n",
    "    x_test = x[22:29]\n",
    "    y_test = y[22:29]\n",
    "    del x, y\n",
    "\n",
    "    # add augmentations\n",
    "    import albumentations as A\n",
    "\n",
    "    transform_light = A.Compose([\n",
    "        A.HorizontalFlip(p=1),\n",
    "        A.RandomBrightnessContrast(p=1, brightness_by_max=False,\n",
    "                                   contrast_limit=(-config.aug_contrast_light, config.aug_contrast_light),\n",
    "                                   brightness_limit=(-config.aug_brightness_light, config.aug_brightness_light)),\n",
    "        A.MultiplicativeNoise(p=1, multiplier=(1 - config.aug_noise_light, 1 + config.aug_noise_light),\n",
    "                              elementwise=False),\n",
    "        A.PixelDropout(p=1, dropout_prob=config.aug_dropout_light)\n",
    "    ])\n",
    "    transform_middle = A.Compose([\n",
    "        A.VerticalFlip(p=1),\n",
    "        A.RandomBrightnessContrast(p=1, brightness_by_max=False,\n",
    "                                   contrast_limit=(-config.aug_contrast_middle, config.aug_contrast_middle),\n",
    "                                   brightness_limit=(-config.aug_brightness_middle, config.aug_brightness_middle)),\n",
    "        A.MultiplicativeNoise(p=1, multiplier=(1 - config.aug_noise_middle, 1 + config.aug_noise_middle),\n",
    "                              elementwise=False),\n",
    "        A.GaussianBlur(p=1),\n",
    "        A.PixelDropout(p=1, dropout_prob=config.aug_dropout_middle)\n",
    "    ])\n",
    "    transform_hard = A.Compose([\n",
    "        A.RandomCrop(width=150, height=150),\n",
    "        # A.ElasticTransform(p=1),\n",
    "        A.GaussianBlur(p=1),\n",
    "        A.RandomBrightnessContrast(p=1, brightness_by_max=False,\n",
    "                                   contrast_limit=(-config.aug_contrast_hard, config.aug_contrast_hard),\n",
    "                                   brightness_limit=(-config.aug_brightness_hard, config.aug_brightness_hard)),\n",
    "        A.MultiplicativeNoise(p=1, multiplier=(1 - config.aug_noise_hard,\n",
    "                                               1 + config.aug_noise_hard), elementwise=True),\n",
    "        A.PixelDropout(p=1, dropout_prob=config.aug_dropout_hard),\n",
    "        A.PadIfNeeded(min_height=224, min_width=224, p=1)\n",
    "    ])\n",
    "\n",
    "    aug_list = [transform_light, transform_middle, transform_hard]\n",
    "\n",
    "    pict_with_labels = zip(x_train.copy(), y_train.copy())\n",
    "    for image, mask in pict_with_labels:\n",
    "        for aug in aug_list:\n",
    "            transformed = aug(image=image, mask=mask)\n",
    "            x_train.append(transformed['image'])\n",
    "            y_train.append(transformed['mask'])\n",
    "\n",
    "    # Transform Data to tensor\n",
    "    x_train = tf.convert_to_tensor(x_train, dtype=float16)\n",
    "    y_train = tf.convert_to_tensor(y_train, dtype=float16)\n",
    "    x_test = tf.convert_to_tensor(x_test, dtype=float16)\n",
    "    y_test = tf.convert_to_tensor(y_test, dtype=float16)\n",
    "\n",
    "    # define number of channels\n",
    "    N = x_train.shape[-1]\n",
    "\n",
    "    # define model\n",
    "    model = Unet(backbone_name=config.backbone, encoder_freeze=config.encoder_freeze, encoder_weights=None,\n",
    "                 input_shape=(None, None, N), activation=config.activation,\n",
    "                 classes=len(labels))\n",
    "\n",
    "    # model.summary()\n",
    "    model.compile(optim, loss=loss, metrics=metrics)\n",
    "\n",
    "    # train\n",
    "    model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,  # config.batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_test, y_test),\n",
    "        callbacks=[WandbCallback()]\n",
    "    )\n",
    "    # make predictions train\n",
    "    y_train = tf.reshape(tf.math.argmax(y_train, axis=3), [-1]).numpy()\n",
    "    pred_y_train = model.predict(x_train)\n",
    "    pred_y_train = tf.reshape(tf.math.argmax(pred_y_train, axis=3), [-1]).numpy()\n",
    "\n",
    "    # make predictions test\n",
    "    y_test = tf.reshape(tf.math.argmax(y_test, axis=3), [-1]).numpy()\n",
    "    pred_y_test = model.predict(x_test)\n",
    "    pred_y_test = tf.reshape(tf.math.argmax(pred_y_test, axis=3), [-1]).numpy()\n",
    "\n",
    "    labels_train = np.unique(np.concatenate((y_train, pred_y_train)))\n",
    "    labels_test = np.unique(np.concatenate((y_test, pred_y_test)))\n",
    "\n",
    "    # calculate and log metrics\n",
    "    precision_train = precision_score(y_train, pred_y_train, labels=labels_train, average='micro')\n",
    "    precision_test = precision_score(y_test, pred_y_test, labels=labels_test, average='micro')\n",
    "\n",
    "    recall_train = recall_score(y_train, pred_y_train, labels=labels_train, average='micro')\n",
    "    recall_test = recall_score(y_test, pred_y_test, labels=labels_test, average='micro')\n",
    "\n",
    "    f1_train = f1_score(y_train, pred_y_train, labels=labels_train, average='micro')\n",
    "    f1_test = f1_score(y_test, pred_y_test, labels=labels_test, average='micro')\n",
    "\n",
    "    labels_test_str = operator.itemgetter(*labels_test)(labels)\n",
    "    wandb.log(\n",
    "        {\"conf_mat\": wandb.plot.confusion_matrix(probs=None, y_true=y_test, preds=pred_y_test,\n",
    "                                                 class_names=labels_test_str)})\n",
    "\n",
    "    wandb.log({'precision_train': precision_train})\n",
    "    wandb.log({'precision_test': precision_test})\n",
    "\n",
    "    wandb.log({'recall_train': recall_train})\n",
    "    wandb.log({'recall_test': recall_test})\n",
    "\n",
    "    wandb.log({'f1_train': f1_train})\n",
    "    wandb.log({'f1_test': f1_test})\n",
    "    print(\"Finshed Job\")\n",
    "    wandb.finish()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "    Better use Sweep_upload_data.ipynb to avoid errors and bad visualisation\n",
    "    \"\"\"\n",
    "\n",
    "    # define sweep_id\n",
    "    sweep_id = 'ovzbvxa7'\n",
    "    # wandb sweep sweep.yaml\n",
    "\n",
    "    # run the sweep\n",
    "    wandb.agent(sweep_id, function=cnn_sweep, project=\"cnn_segmentation_models\", entity=\"pds_project\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from sharedtask02.Model.model import load_data, create_traindataset\n",
    "\n",
    "\n",
    "train, sampleTest, sampleSubmission = load_data()\n",
    "x_train, y_train, x_test, y_test = create_traindataset(train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# Read in the csv data using pandas\n",
    "def load_data():\n",
    "    train = pd.read_csv('../data/01_train/train.csv',header=None)\n",
    "    sampleTest   = pd.read_csv('../data/01_train/sampleTest.csv')\n",
    "    sampleSubmission  = pd.read_csv('../data/01_train/sampleSubmission.csv')\n",
    "    return train,sampleTest,sampleSubmission"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "# load data\n",
    "train, sampleTest, sampleSubmission = load_data()\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "train_scaled = sc.fit_transform(train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "n_future = 7 # next 4 days temperature forecast\n",
    "n_past = 90 # Past 90 days\n",
    "for j in range(0,len(train_scaled)):\n",
    "    for i in range(0,len(train_scaled[j])-n_past-n_future+1):\n",
    "        x.append(train_scaled[j,i : i + n_past ])\n",
    "        y.append(train_scaled[j,i + n_past : i + n_past + n_future ])\n",
    "x , y = np.array(x), np.array(y)\n",
    "x = np.reshape(x, (x.shape[0] , x.shape[1], 1) )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "n_future = 7 # next 4 days temperature forecast\n",
    "n_past = 90 # Past 30 days\n",
    "n_overlap=3\n",
    "overlap=[]\n",
    "for i in range(1,n_overlap+1):\n",
    "    temp=int(n_past-(n_past/n_overlap)*(i))\n",
    "    overlap.append(temp)\n",
    "\n",
    "for j in range(0,len(train_scaled)):\n",
    "    for i in range(0,(len(train_scaled[j])-n_past-n_future+1)):\n",
    "        for o in overlap:\n",
    "            von=i+o\n",
    "            bis=i+o + n_past\n",
    "            if(len(train_scaled[j,von : bis ])==90 and len(train_scaled[j,bis : bis + n_future ])==7):\n",
    "                x_train.append(train_scaled[j,von : bis ])\n",
    "                y_train.append(train_scaled[j,bis : bis + n_future ])\n",
    "\n",
    "#Ah = np.vstack(x_train)\n",
    "#Av = np.hstack(x_train)\n",
    "#x_trainl=x_train\n",
    "x_train , y_train = np.array(x_train), np.array(y_train)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0] , x_train.shape[1], 1) )\n",
    "x=x_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense ,Dropout\n",
    "# Fitting RNN to training set using Keras Callbacks. Read Keras callbacks docs for more info."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional, RNN, SimpleRNN\n",
    "\n",
    "\n",
    "def load_model(x_train):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(SimpleRNN(units=2, return_sequences=True, input_shape = (x_train.shape[1],1) ) ))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units= 2 , return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units= 2 , return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(SimpleRNN(units= 2))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = n_future,activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error',metrics=['acc','mean_squared_error'])\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31986, 90, 1)\n",
      "(31986, 7)\n",
      "(31986, 90, 1)\n",
      "(31986, 7)\n",
      "Epoch 1/200\n",
      " 22/125 [====>.........................] - ETA: 7s - loss: 0.4113 - acc: 0.1474 - mean_squared_error: 0.4113"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [47], line 20\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(y_test\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m     19\u001B[0m model\u001B[38;5;241m=\u001B[39mload_model(x_train)\n\u001B[1;32m---> 20\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m256\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mc:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\keras\\engine\\training.py:1564\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1556\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1557\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1558\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1561\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1562\u001B[0m ):\n\u001B[0;32m   1563\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1564\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1565\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1566\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32mc:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mc:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32mc:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateless_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32mc:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2494\u001B[0m   (graph_function,\n\u001B[0;32m   2495\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2496\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1858\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1859\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1860\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1861\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1862\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1863\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1864\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1865\u001B[0m     args,\n\u001B[0;32m   1866\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1867\u001B[0m     executing_eagerly)\n\u001B[0;32m   1868\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32mc:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32mc:\\users\\vdwti\\pycharmprojects\\shared-tasks-wintersemester-2022-23\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# import model_selection module of scikit-learn\n",
    "from sklearn import model_selection\n",
    "# initiate the k-fold class from model_selection module\n",
    "splits=2\n",
    "#for i in range(splits):\n",
    "kf = model_selection.KFold(n_splits=splits,shuffle=True)\n",
    "for fold, (trn_, val_) in enumerate(kf.split(X=x)):\n",
    "    #split dataset\n",
    "    x_train=x[trn_]\n",
    "    y_train=y[trn_]\n",
    "    x_test=x[val_]\n",
    "    y_test=y[val_]\n",
    "\n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(x_test.shape)\n",
    "    print(y_test.shape)\n",
    "\n",
    "    model=load_model(x_train)\n",
    "    model.fit(x_train, y_train, epochs=200,batch_size=256,validation_data=(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_temperature = model.predict(x_test)\n",
    "predicted_temperature = sc.inverse_transform(predicted_temperature)\n",
    "#predicted_temperature = np.reshape(predicted_temperature,(predicted_temperature.shape[1],predicted_temperature.shape[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicted_temperature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dif=y_test-predicted_temperature\n",
    "dif"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "\n",
    "mean(abs(dif))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}