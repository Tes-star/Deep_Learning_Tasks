{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "import numpy  as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read in the csv data using pandas\n",
    "train  = pd.read_csv('../input/santander-customer-satisfaction/train.csv',index_col=0)\n",
    "test   = pd.read_csv('../input/santander-customer-satisfaction/test.csv', index_col=0)\n",
    "sample = pd.read_csv('../input/santander-customer-satisfaction/sample_submission.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train.dtypes.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train.select_dtypes(include=['int64']).nunique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features_to_drop = train.nunique()\n",
    "features_to_drop = features_to_drop.loc[features_to_drop.values==1].index\n",
    "# now drop these columns from both the training and the test datasets\n",
    "train = train.drop(features_to_drop,axis=1)\n",
    "test  = test.drop(features_to_drop,axis=1)\n",
    "train.isnull().values.any()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled,\n",
    "                                                  train_size=0.5,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=42,\n",
    "                                                  shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler  = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val   = scaler.transform(X_val)\n",
    "test    = scaler.transform(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=9, activation=\"relu\", input_shape=(X_train.shape[-1],) ),\n",
    "        # randomly delete 30% of the input units below\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(units=9, activation=\"relu\"),\n",
    "        # the output layer, with a single neuron\n",
    "        keras.layers.Dense(units=1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# save the initial weights for later\n",
    "initial_weights = model.get_weights()\n",
    "model.summary()\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=keras.metrics.AUC()\n",
    "             )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    min_delta = 0.0002, # minimium amount of change to count as an improvement\n",
    "    patience  = 20,     # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "model.set_weights(initial_weights)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "          epochs=500,\n",
    "          batch_size=1000,\n",
    "          validation_data=(X_val, y_val),\n",
    "          verbose=0,\n",
    "          # add in our early stopping callback\n",
    "          callbacks=[early_stopping]\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample['TARGET'] = model.predict(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}